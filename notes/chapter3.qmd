# The Core Concepts of Probability
## Assigning Probabilities and The Equally Likely Outcome Model
There are a plethora of ways to assign probabilities to different events. At the most basic of levels any rule that maps from the space of possible events to numbers between $0$ and $1$ are possible candidates for probability assignment. That is, probability assignment at its core is simply a set of rules which says "for this event, assign this probability."

TODO: Add example of coin toss space.

Not every assignment of probability values is going to be valid. Suppose, for instance, that we have a six-sided die, each side labelled with a number from one to six. If I told you that there was a probability of $0.5$ that it comes up $1$, $0.5$ that it comes up $2$, $0.5$ that it comes up $3$, $0.5$ that it comes up $4$, $0.5$ that it comes up $5$ and $0.5$ that it comes up $6$, you  would probably call me a liar (or else conclude that I was mistaken and likely should not be teaching probability). If, as we have previously seen, probabilities represent the long-run proportion of time that a particular event is observed, we cannot have $6$ different outcomes each occurring in half of all cases.

beyond the requirements that we can impose on what constitutes a "valid" probability function, we have another concern: scalability. It is perfectly acceptable to indicate that in an experiment with $3$ outcomes, the first has a probability of $0.25$, the second of $0.3$, and the third of $0.45$. What if the experiment has $100$ possible outcomes? Or $1000$?It quickly becomes apparent that enumerating the probabilities of each event in the sample space is an efficient way of assigning probabilities in practice.

A core focus of our study of probability will be on finding techniques that allow us to efficiently encode probability information into manageable objects. Once we have done this, we will be in a position where we can manipulate these (comparatively) simple mathematical quantities in order to make statements and conclusions about any of the events of interest, even if they have never been explicitly outlined as having an assigned probability.

While we will consider myriad methods for accomplishing these goals throughout our study of probability, we begin  with a very useful model which simplifies probability assignment,  without any added complexity,  and creates a solid foundation for us to explore the properties of probability models. We start by considering **equally likely outcomes.** As the name suggests, the probability model considering equally likely outcomes assigns an equal probability to every possible outcome of the experiment. This is a probability model that we are already distinctly familiar with: flipping a coin, rolling a die, or drawing a card are all examples of experiments which rely on the equally likely outcomes framework.

TODO: Write aside about the use of urn models.

If we have an experiment with a sample space $\mathcal{S}$ which has $|\mathcal{S}| = k$ total elements, then each element of the sample space occurs with probability $\frac{1}{k}$. In the case of the coin toss example, $\mathcal{S} = \{\text{H}, \text{T}\}$, and so $k=2$ and each outcome occurs with probability $\frac{1}{2}$. in the case of drawing a card at random, there are $52$ different outcomes, and so $k=52$, and the probability of drawing any particular card is $\frac{1}{52}$.

It is critically important to recognize that the equal probability model assigns equal likelihood to the possible outcomes of an experiment, not the possible  events of interest. It will not be the case in general that all events have the same probability. To make this concrete, consider the events $A$ "the ace of spades is drawn" and $B$ "any spade is drawn". It is quite clear that $B$ happens more frequently than $A$, even though we have said that this is an experiment with equally likely outcomes. Remember: an outcome is an observation from a single experimental run, an event is any subset of these possible outcomes.

A core goal is then bridging the gap between the probability of an outcome - something which in the equally likely outcomes framework we know - and the probability of an event - the quantity we are actually interested in. In order to do so, we will next consider the rules of probability, introducing the properties that are required for valid probability assignments and the techniques for  manipulating probabilities to calculate the quantities of interest.

## Rules of Probability
We have previously seen that not every probability assignment can be valid. For instance, assigning $0.5$ probability to each outcome on a die leads to a nonsensical scenario. with just a little imagine we can conjure equally nonsensical scenarios in other regards. For instance, it would make very little sense to discuss the probability of an event being a negative value. What would it mean for an event to occur in a negative proportion of occurrences? Alternatively, we can consider two events that are nested in one another: say event $A$ is that we draw the ace of spades, and event $B$ is that we draw any spade. Every single time that $A$ happens, we know that $B$ also happens. But there are ways that $B$ can occur where $A$ does not (for instance, the Queen of spades being drawn). If I told you the probability of $A$ was $0.5$ and the probability of $B$ was $0.2$, this would violate our base instincts: how can it be more likely to draw the ace of spades than it would be to draw any spade at all?

Often in mathematics when we have an intuitive set of rules that particular quantities must obey, we work to add formality through defining properties of these concepts. To this end, we can define the key properties that probabilities must obey in order to be well-defined, valid probabilities.

It turns out that with three (fairly) basic properties, we can completely specify what must be true in order for a set of probabilities to be valid. 

1. **Unitary** Every valid set of probabilities must assign a probability of $1$ to the full sample space. That is, $P(\mathcal{S}) = 1$. This is an intuitive requirement as  every  time the experiment is run we observe an outcome in the sample space, and as  a result, in every experimental run the event $\mathcal{S}$ occurs.
2. **Non-negative:** We require that every probability is non-negative. We can have probabilities of $0$, but we can never have a probability less than zero. Again, this is sensible (what would it mean to have a negative probability?), but is important to include in our formalization. Specifically, for every event $E$, $P(X) \geq 0$.
3. **Additivity:** the final property  requires slightly more parsing on first pass. Suppose that we define a sequence of events,  $E_1, E_2, E_3, \dots$ such that no two events have any overlap. That is, $E_j \cap E_\ell = \emptyset$ for all $\ell\neq j$. Then, the final property we require for probabilities is that $$P\left(\bigcup_i E_i\right) = \sum_i P(E_i).$$ That is, the probability of the union of disjoint events is the summation of the probability of these events.

It is worth dwelling slightly on property (or axiom) 3 further. Consider the case of drawing a card at random from a deck of $52$ cards. Using the equally likely outcome model for probability we know that the probability that any card is drawn is given by $\frac{1}{52}$. If I were to ask  "what is the probability you draw that ace of spades?" under this model you can respond, immediately,  with $\frac{1}{52}$. Now, if I were to ask "what is the probability that you draw the ace of spades or two  of spades?" intuitively you likely figure that this will be $\frac{2}{52}$. Note that the event $E_1$, "draw the ace of spades" and the event $E_2$ "draw the two of spades", are disjoint events. Moreover, recall that the union is the "or" and so $E_1\cup E_2$ is the same as $E_1$ or $E_2$. Taken together then, $$P(E_1\cup E_2) = P(E_1) + P(E_2).$$ The axiom of additivity simply extends this intuition to an arbitrary number of events.

TODO: insert example about additivity.

These three axioms fully define valid probabilities. Any mechanism that assigns probability values to events which conforms to these rules will assign valid probabilities. While it may seem counter intuitive that such basic rules fully define our notion of a probability, these rules readily give rise to many other properties that are indispensible when working with probabilities.

## Secondary Properties of Probabilities
1. $P(E^C) = 1-P(E)$, and equivalently, $P(E) = 1 - P(E^C)$.
2. $P(\emptyset) = 0$.
3. $P(E_1 \cup E_2) = P(E_1) + P(E_2) - P(E_1\cap E_2)$.
4. $P(E_1 \cup E_2 \cup E_3) = P(E_1) + P(E_2) + P(E_3) - P(E_1\cap E_2) - P(E_1 \cap E_3) - P(E_2 \cap E_3) + P(E_1 \cap E_2 \cap E_3)$.
5. $P(\bigcup_i E_i) \leq \sum_i P(E_i)$.

TODO: write aside that proves these from the basic properties.

TODO: am I missing any?

These properties are immensely useful when computing probabilities. in fact, these secondary properties will be used with more frequency than the basic axioms when manipulating probabilities in practice. It is worth building comfort with these properties, early and often, as they will assist in manipulating all probability expressions in the future. 

TODO: Example showing complement trick.

While these properties hold in general for all probability models, it is instructive to consider to focus on the equal probability model to begin building familiarity with probability broadly. These properties allow us to take events -- whether compound or simple -- and combine, rewrite, and manipulate expressions to assist in the handling of the computations. Eventually, however, we require the ability to  assign numerical values to these probabilities.

Consider a simple event, $A$. Recall that a simple event is defined as  a possible outcome of an experiment, and so in this case,  $A$ corresponds directly to an event that may be observed. If our sample space is $k$ elements large, then $P(A) = \frac{1}{k}$ in this framework. For instance, if $A$ is the event that a two is rolled on a six-sided fair die, then $P(A) = \frac{1}{6}$. 

Now, suppose that a compound event is defined, $B$. By definition, a compound event can be expressed as a set of possible outcomes from the experiment. Suppose that we enumerate these possible events as $b_1, b_2, \dots, b_\ell$. Then we know that $B$ occurs if any of $b_1,b_2,\dots,b_\ell$ occur. Each $b_j$ are elements of the sample space and correspond to possible outcomes of the experiment. As a result, we know that $P(b_j) = \frac{1}{k}$, based on the equal probability assumption. Now, if we take any two distinct $b_j$, say $b_i$ and $b_j$, we know that they must be disjoint: $b_i \cap b_j = \emptyset$. This is because in an experiment run only one outcome can occur -- there is nothing common between these two events, by definition. Moreover, we can say that $B = b_1 \cup b_2 \cup\cdots\cup b_\ell$.

Using the axioms of probability outlined above we therefore know that $P(B) = \sum_{j=1}^\ell P(b_j) = \sum_{j=1}^\ell \frac{1}{k} = \frac{\ell}{k}$. This holds in general for any compound event in  this setting. If we take $B$ to be the event that an even number is rolled on a six-sided die, then we would have $b_1$ is the event that a two is rolled, $b_2$ is the event that a four is rolled, and $b_3$ is the event that a six is rolled. There are three such events, and so the probability that an even number is rolled must be $\frac{3}{6} = 0.5$, which matches our intuition.

If we consider what this process  is doing at its core, we can reframe the calculation as counting up the number of ways that event can happen and dividing by the total number of events. In our previous discussion, there were $\ell$ ways of $B$ occurring, a total of $k$ outcomes, and so the probability becomes $\frac{\ell}{k}$. in the equal probability model, this will always be the case, the probability of any event $A$ occurring is given by $$P(A) = \frac{N_A}{k},$$ where $N_A$ is the number of unique ways that $A$ can occur.  In other words, $N_A$ is the size of the set $A$.

As a result of the realization, a large part of computing probabilities is in the counting of possible outcomes corresponding to different events. If we can determine the count of $A$, $N_A$, and the count of the total number of occurrences, $k$, then we can determine the probability of $A$. This study of counting is known as **combinatorics**, and it is where we will turn our attention next.

TODO: include example that shows  the utility of complements,  again.  Show specifically for counting where,  for instance, the complement is very small and is easier to count. 

## Combinatorics
Fundamentally, counting is a matter of assessing the size of a collection of items. Sometimes, this is very straightforward: if you want to count the number of students in a classroom, you  start  at $1$ and enumerate upwards through the integers. To count the number of days until the next Holiday, you do the same thin, sizing up the time that has to pass. If you really need to sleep, perhaps you will count imaginary sleep until you drift off. There is not much to this type of counting, and it is certainly deeply familiar to you all. However, it is also quite limited in its utility.

Imagine that you are interested in determining how many possible ways there are of arranging a deck of $524 cards. You could of course arrange them in a particular order, then count each of those. That would take a tremendous amount of time, so perhaps instead of using an actual deck you just write down the combinations. Still, each combination is going to be $52$ cards long, and keeping track of that all will be a tremendous challenge. This seems like an approachable question, and yet, it illustrates how complicated (and large) these types of "counting" problems can become, very quickly.

Fortunately for us there are some strategies for simplifying these problems down, some of which you are likely already familiar with. Think about trying to form an outfit where you have $4$ different sweaters, $3$$ pairs of pants, and $2$ options for your shoes. Suppose that any combination of these will work well. How many are there? Well, if you have already picked your sweater and pants, then there are going to be $2$ different outfits using these: one with each of the pairs of shoes. This is true for each possible sweater-pant combination, and so we can count $2$ for each one these. In other words, to get the total number of outfits we multiply the number of sweater pant combinations by the number of shoe options ($2$). the same rationale can be applied to count the total number of sweater-pant combinations. For each sweater, there are $3$ pairs of possible pants, and so to get the total number there we can take $3$ for each possible sweater, or in other words, #3\times 4$. 

Taken together then we have $4\times 3\times 2 = 24$ total possible outfits. Another way of framing this is that we have to make three sequential decisions: which of the $4$ sweaters, which of the $3$ pants, and which of the $2$ shoes are to be worn. When we do this we multiply through the number of alternatives at each decision point to get the total number of combinations.

This is known as the **multiplication rule for counting**, and it is a very general rule for counting up total combinations. Any time that we have to make a sequence of $k$ choices, and each choices $j=1,\dots,k$ has $n_j$ options, then the total number of combinations will be $N = n_1\times n_2\times\cdots\times n_k$.

TODO: add examples for the counting rule.

Sometimes it is helpful to express the counting rule graphically. To do so we rely on **tree diagrams**. A tree diagram puts each of the decisions in sequence, and draws a branch for each separate option. You start with the first choice, drawing one branch for each of the $n_1$ alternatives, labelling each. Then, at the second choice, you do the same process at the end of each of the branches you drew for choice $1$, this time drawing $n_2$ branches there (so you will have just drawn $n_1\times n_2$ branches). Then for each of those you draw the $n_3$ further branches, and so on and so forth until the end. 

If you want to know the total number of choices, you simply count the end points at the very end of the diagram. Each branch corresponds to a single option. To determine which combination of choices it corresponds to, you simply read off the branch labels at each branch you take. If you want to know how many possible combinations come with certain options selected, you can look at only those branches which are downstream from the choices that you care about.

TODO: include tree diagram.

While tree diagrams can be quite useful for visualizing a problem, they often grow to be overly complex. As a result, we often need to fall back on the numerical representation afforded to us through the product rule for counting. Counting problems, in general, can very quickly become tremendously large and complex. For this reason, we have several tools to assist us in reducing this complexity based on common types of problems that we would like to count.

The first useful tool for simplifying these problems is the **factorial**. The factorial of an integer, denoted by $x!$ (factorials are exciting because they always look like they are shouting!) is given by the product of all integers from $x$ to $1$. That is, $x! = x(x-1)(x-2)\cdots(2)(1)$. If we consider the product rule for counting then note that if $n_1=1$, $n_2=2$, ... , $n_k = k$, then the total number of options is $k\times(k-1)\times\cdots\times 1 = k!$. The most common reason that this comes up is when we want to order a collection of items. Suppose that you have $10$ books that you want to place on a shelf. You can view this as making $10$ sequential decisions: what book goes first, second, third, and so on. There are $10$ options for the first book, then $9$ for the second (any except for the first one), and then $8$ for the third (any except for the first $2$). This continues down to the last book, and so we conclude that there are $10\times9\times8\times\cdots\times1 = 10!$ ways of arranging these books.

TODO: Additional example on factorial.

Sometimes, we want to still order items from a collection, but we want to only use a subset of these times. That is, suppose that you have $20$ books, only $10$ of them will fit on the self, and so you want to know: how many ways can you put $10$ books on the shelf, in order, from your collection of $20$. Using the product rule of counting for this directly  we can recognize that there are $20$ options for the first, then $19$, then $18$, and so on until there are $11$ choices for the $10$th book to place. We can write this out in a seemingly strange way. $$\frac{20(19)(18)(17)(16)(15)(14)(13)(12)(11)(10)(9)(8)(7)(6)(5)(4)(3)(2)(1)}{10(9)(8)(7)(6)(5)(4)(3)(2)(1)}.$$

This expression is $20!$ divided by $10!$, and gives the same as our argument from the product rule for counting directly. This is a more general result than our example with books would suggest. If we have $n$ items, and we want to choose $k$ of them and then order those choices, it will always be $n!$ divided by $(n-k)!$. We call this a **permutation**. Formally, we write $$P_{n,k} = \frac{n!}{(n-k)!}.$$

Permutations arise when we select ordered subsets from a collection. We often, in combinatorial problems, talk about ordering, though sometimes what we mean by this is slightly more abstract. Suppose that you want to form a committee with $5$ different people, each of which occupies a different role: the president, vice president, treasurer, note taker, and critic. If there are $30$ people to select for this, then there are $P_{30,5}$ total possible committees that can be formed. While there is not a sequential order here, we talk about this as being ordered since we can differentiate between the five roles. Instead of labelling them with their names, we could label them $1$ through $5$ and make the ordering more explicit. 

TODO: include additional example on permutations.
TODO: 0! = 1.

Factorials compute the number of orderings for a set of objects, and permutations compute the number of ordered subsets from a collection of objects. What about when we do not wish to differentiate the order of subsets? Suppose that you still need to form a $5$ person committee, but you do not have explicit roles for the different members of the committee. Here we cannot use a permutation directly, as we know that this takes into account the order. Suppose that we formulate the ordered committee in a separate way: first, we select $5$ people without concern for their order, then we choose which order they will have.

If $M$ represents the number of unordered sets of $5$ from this population, the product rule for counting tells us that the total number of ordered committees will be $M\times 5!$, since there are $5!$ arrangements. Thus, we can write this down as $$P_{30,5} = \frac{30!}{25!} = M\times 5! \implies M = \frac{30!}{25!5!}.$$ Once again, this will be true far more broadly than our committee example: if we want to select $k$ items from a collection of $n$, we will have $n!$ divided by the product of $k!$ and $(n-k)!$. We refer to these as **combinations**. 

We will write $\binom{n}{k}$, which we read as "$n$ choose $k$", which translates to "select $k$ items from a population of $n$ total options, without concern for their order." Formally, a combination is defined as $$\binom{n}{k} = \frac{n!}{k!(n-k)!}.$$

To summarize: factorials allow us to order a complete collection, permutations allow us to select a subset with consideration of the ordering, and combinations allow us to select a subset from the collection without regard to the order. These three techniques can be used in combination with the product rule for counting to allow us to have very complex total summations. 

TODO: introduce example for combinations.
TODO: introduce extended examples for counting, mixing the different techniques. 

There are other types of counting problems which occasionally need to be considered. [TODO: include counting with replacement].

While combinatorics is a field of study on its own, with many intriguing tools and developments surrounding the enumeration of objects, for the purposes of simple probability models these tools will suffice. Ultimately, we care about counting since in the equal probability model, the probability of any event can be determined by counting the number of ways that the event can occur and dividing by the total number of outcomes that are possible. That is, we use these tools to derive $N_A$, the total number of ways that $A$ can occur, and $N$, the total number of experimental outcomes, and then we conclude that $$P(A) = \frac{N_A}{N}.$$

TODO: include brief probability example.