<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.533">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>STAT 1793: Course Notes - 5&nbsp; Random Variables</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../notes/chapter6.html" rel="next">
<link href="../notes/chapter4.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "classic",
  "enableExperimentalNewNoteButton": true,
  "showHighlights": "whenSidebarOpen"
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notes/chapter1.html">Part 1: Probability</a></li><li class="breadcrumb-item"><a href="../notes/chapter5.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Random Variables</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">STAT 1793: Course Notes</a> 
        <div class="sidebar-tools-main">
    <a href="../STAT-1793--Course-Notes.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Part 1: Probability</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Mathematical Foundations of Statistical Experiments</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Core Concepts of Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Probailities with More than One Event</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter5.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Random Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The Named Discrete Distributtions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Part 2: Statistics</span></span>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#independent-and-identically-distributed-a-framework-for-interpretation" id="toc-independent-and-identically-distributed-a-framework-for-interpretation" class="nav-link active" data-scroll-target="#independent-and-identically-distributed-a-framework-for-interpretation"><span class="header-section-number">5.1</span> Independent and Identically Distributed: A Framework for Interpretation</a></li>
  <li><a href="#expectation" id="toc-expectation" class="nav-link" data-scroll-target="#expectation"><span class="header-section-number">5.2</span> Expectation</a></li>
  <li><a href="#conditional-and-joint-expectations-and-variances" id="toc-conditional-and-joint-expectations-and-variances" class="nav-link" data-scroll-target="#conditional-and-joint-expectations-and-variances"><span class="header-section-number">5.3</span> Conditional and Joint Expectations and Variances</a></li>
  <li><a href="#independence-in-all-of-this" id="toc-independence-in-all-of-this" class="nav-link" data-scroll-target="#independence-in-all-of-this"><span class="header-section-number">5.4</span> Independence in all of this</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notes/chapter1.html">Part 1: Probability</a></li><li class="breadcrumb-item"><a href="../notes/chapter5.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Random Variables</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Random Variables</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>When introducing probability originally we worked from a sample space and then corresponding events. This is a very general framework which allows us to effectively capture any statistical experiment that we may want. Sample spaces are not resitrcted to be numeric, for instance, and events are simply subsets of the sample space. As a result, this framewokr provides the tools for capturing uncertainty quantification in just about every setting that we may desire. Still, the need to enumerate sample sapces adn events over complex sets of arbitrary items is cumbersome and may prevent succinct representations of the underlying phenomenon. Often, rather than caring about the entire space out outcomes from an experiment of interest, we are primarily concerned we a summary of the experiment.</p>
<p>When we can summarize the experiment using a numerical quantity, we are able to define a <strong>random variable</strong>. Arandom variable is simply a numeric quantity whose speciifc value depends on chance, through the outcome of a statistical experiment. Specifically, a random variable is a mapping from the result of an experiment to a set of numbers, and by reporting the numeric value of the random variable, we are able to summarize the key part of the experiment, succinctly.</p>
<p>For instance, suppose that we are repeatedly tossing a coin. If we toss the coin <span class="math inline">\(1100\)</span> times, then the sample space is going to consist of <span class="math inline">\(2^{100}\)</span> total possible outcomes, each of which is a sequence of <span class="math inline">\(100\)</span> heads and tails. Instead, it may be more convenient to assign a random varaible to be the number of heads that show up on the <span class="math inline">\(100\)</span> tosses of the coin. In this case, the random variable takes on a non-negative integer between <span class="math inline">\(0\)</span> and <span class="math inline">\(100\)</span>. In many situations, such a summary may be all the is relevant from the experiment.</p>
<p>TODO: Include an example of random variables.</p>
<p>because of their ability to summarize effectively the components of a random experiment that we care about, random variables will become the default paradigm for discussing randomness going forward. Wehn discussing a random variable we will typically use capital letters, <span class="math inline">\(X\)</span>, to represent the random quantity with an unknown value. In the event that an experiment is actually performed, and a value is realized for a random variable, we will record this value as a lower case letter, such as <span class="math inline">\(x\)</span>. For instance, the number of heads showing in <span class="math inline">\(100\)</span> flips of a coin is an unknown quantity depending on chance, which we call <span class="math inline">\(X\)</span>. Once we have flipped the coin <span class="math inline">\(100\)</span> times and observed <span class="math inline">\(57\)</span> heads, we denote this as <span class="math inline">\(x=57\)</span>.</p>
<p>The importance of this notation is merely to emphasize what values are unknown and random, and what values are simply numeric quantities. because <span class="math inline">\(x\)</span> is a known value, taking on some set number, we will not often speak of probabilities involving <span class="math inline">\(x\)</span>. Instead, we wish to translate the language of probability that we have built to statements regarding the random variable <span class="math inline">\(X\)</span>.</p>
<p>The random variable <span class="math inline">\(X\)</span> has a corresponding sample space of possible values that it can take on. This sample space, which we can think of as directly analogous to the sample space of arbitrary elements from before, will be dictated by the possible realizations from the underlying experiment. Then, after the experiment has been performed, the random variable will take on a single value from this set. Often we are able to very compactly describe the set of possible values for a random variable, for instance, by stating all of the integers, or integers between <span class="math inline">\(5\)</span> and <span class="math inline">\(10\)</span>, or even vvalues less than <span class="math inline">\(1000\)</span>. The probability of realizing any of these outcomes is then, just as in the case of the arbitrary sample space, dictated by the underlying probability model.</p>
<p>When introducing the concepts of probability we indicated that probability was assigned to events. When using random variables we still use this convention, and as a result, we need to define events in terms of random variables. When we have a random variable, <span class="math inline">\(X\)</span>, an event is defined as any set of values that it can take on. For instance, we may have the event <span class="math inline">\(X=4\)</span>, or the event <span class="math inline">\(X \geq 18\)</span>, or the event <span class="math inline">\(2 \leq X \leq 93\)</span>, or the event <span class="math inline">\(X \in \{2,4,6,8,10\}\)</span>. In each case these are simply subsets of the possible outcomes that can be observed on the experiment, once summarized through the lens of the random variable.</p>
<p>Note that, just as was the case before, these events can be though of as being compound events (comprising of multiple outcomes) or simple events (comprised of a single outcome). The event <span class="math inline">\(\{X=5\}\)</span> is a simple event, whereas the event <span class="math inline">\(\{X \geq 25\}\)</span> is a compound event. With events defined in this way, we can translate all of the other concepts over from before. Specifically, we merely think of the experiment as an experiment producing a numerical outcome, and then use the same sets of tools as we did before, applied to numeric events.</p>
<p>TODO: Include example recapping previous discussions with regarding the random variables.</p>
<p>When considering random variables there is a key distinction between two types of random variables: discrete and continuous. A discrete random variable is a random variable which takes values from a countable set of possiblevalues. When we say countable we mean that there are either a finite number of possible values that it can take on (say <span class="math inline">\(\{1,2,\dots,31415\}\)</span>) or an infinite number of possible values, but values that can all be written out in sequence (say <span class="math inline">\(1,2,3,4,\dots\)</span> or <span class="math inline">\(2,4,5,6,8,10,\dots\)</span>). Continuous random variables, on the other hand, are random variables which take on values from an uncountably infinite set of values. Typically this will be expressed as random varaibles which can take on any value in some interval (or set of intervals), such as <span class="math inline">\(X \in [0,1]\)</span> or <span class="math inline">\(X \in (0,\infty)\)</span> or <span class="math inline">\(X\in (-\infty,129]\)</span>. In all of these cases there is no way to enumerate the possible set of values that <span class="math inline">\(X\)</span> can take on, and so we say that there are an uncountable number of them.</p>
<p>TODO: Include example regarding discrete and continuous random variables.</p>
<p>We will discuss continuous random variables, and how they differ from the discussions we have had up until this point, shortly. For now, we turn our focus to discrete random variables. One of the major utilities of random variables, as has been previously mentioned, is that they provide a shorthand for summarizing the results of a statistical experiment. To this end, there are also several tools which have been developed relating to random variables which help to expedite the manipulation of ocncepts related to probability calculations.</p>
<p>Chief among these tools is the concept of a <strong>probability distribution</strong>. A probability distribution is a summary of the probabalistic behaviour of a random variable. Distributions capture the underlying random behaviour of the random variables of interest, and in so doing, summarize information regarding the experiment or process that is being considered. When concerned with discrete random variables, we typically summarize probability distributions through the use of a <strong>probability mass function</strong>.</p>
<p>A probability mass function is a mathematical function which maps possible values for a discrete random variable to the probability correspond to that event. That is, if a random variable <span class="math inline">\(X\)</span> can take on the values <span class="math inline">\(x_1,x_2,\dots,x_k\)</span>, a probability mass function is a function <span class="math inline">\(p(x)\)</span> such that <span class="math inline">\(p(x_1) = P(X = x_1)\)</span>, <span class="math inline">\(p(x_2) = P(X = x_2)\)</span>, …, <span class="math inline">\(p(x_k) = P(X=x_k)\)</span>. As a result, once a probability mass function is known, all of the probabalistic behaviour of the random variable can be fully described.</p>
<p>TODO: Include example regarding pmf.</p>
<p>The conditions that we previously outlined for probabilities still must hold when assessing probabilities through a probability mass function. As a result, we know that probabilities are all between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>, and so we must have <span class="math inline">\(0 \leq p(x) \leq 1\)</span>, for all <span class="math inline">\(x\)</span>. Moreover, we know that the probabilities of the sample space must sum to one, and so we must have that <span class="math display">\[\sum_{x\in\mathcal{X}} p(x) = 1,\]</span> where <span class="math inline">\(\mathcal{X}\)</span> is the set of possible values that <span class="math inline">\(X\)</span> can take on.</p>
<p>TODO: include example regarding finding the PMF.</p>
<p>When solving questions related to probabilities using a probability mass function, the same secondary properties apply. Notably, if we want to know <span class="math inline">\(P(X\in A)\)</span>, for some set of possible values <span class="math inline">\(A\)</span>, then we can write <span class="math display">\[P(X\in A) = \sum_{x\in A}p(x).\]</span> This can be particularly helpful, for instance, if we want to know <span class="math inline">\(P(X \leq c)\)</span> for some constant value <span class="math inline">\(c\)</span>. In this case we know that the possible values range from teh smallest value <span class="math inline">\(X\)</span> ccan take on, through to <span class="math inline">\(c\)</span>, giving for instance, <span class="math display">\[P(X\leq c) = \sum_{x=0}^c p(x),\]</span> if <span class="math inline">\(X \geq 0\)</span>. Rules regarding the complements of events continue to hold as well, where for instance, <span class="math inline">\(P(X &gt; c) = 1 - P(X\leq c)\)</span>, giving a useful avenue for simplifying probability calculations.</p>
<p>TODO: Include probability calculations.</p>
<p>With events defined in terms of random variables, we can talk about events as being independent of eachother or mututally exclusive using the same definitions as before. Likewise, we can talk of joint and conditional probabilities, relating to multiple events. With joint probabilities, it is often easiest to combine the event into a single, compound event and find the marginal probability of that event. For instance, if you have the events <span class="math inline">\(X\)</span> is even and <span class="math inline">\(X \leq 15\)</span>, then the intersection of these events is <span class="math inline">\(X \in \{2,4,6,8,10,12,14\}\)</span> (supposing <span class="math inline">\(X &gt; 0\)</span>).</p>
<p>TODO: include example regarding conditional and joint event probabilities.</p>
<p>While we can discuss independence, joint probabilities, and conditional probabilities relating to events on the same random variable, it is often of interest to combine multiple random variables. Sometimes these random variables will be multiple versions coming from the same distribution, and other times they will be coming from multiple different distributions. In either event, frequently our main concern is in summarizing the probabalisitc behaviour of two or more random quantities.</p>
<p>Note that when we talk of a random variable <code>following'' a particular distribution, we are saying that the probability mass function of the random variable is described by that distribution's mass function. Thus, if two random variables</code>share a distribution’’, we just mean that their probabilistic behaviour is described by the same underlying mass function. For instance, if I flip a coin <span class="math inline">\(10\)</span> times, and you flip a different coin <span class="math inline">\(10\)</span> times, and we each count the number of heads that show up, we can say that the random quantity for the number of heads I observe will have the same distribution as the random quantity for teh number of heads that you observe. These two quantities are not equal, in general, but they aredescribed by the same random processes.</p>
<p>When we describe the distribution of a particular random variable, we are implicitly describing the marginal probabilities associated with that quantity. Just as before, the marginal probabilities describe the behaviour of the radnom variable alone. What happens when we want to be able to describe multiple components of an experiment, together? For this we require extending the idea of a joint probability beyond the concept of events.</p>
<p>Suppose that we roll two six-sided fair dice. Let <span class="math inline">\(X\)</span> denote the sum of the two dice, and let <span class="math inline">\(Y\)</span> denote the maximum value showing on the two dice. <span class="math inline">\(X\)</span> is a discrete random variable taking on values between <span class="math inline">\(2\)</span> and <span class="math inline">\(12\)</span>, while <span class="math inline">\(Y\)</span> is a discrete random variable taking on values between <span class="math inline">\(1\)</span> and <span class="math inline">\(6\)</span>. The sample spaces for the two random variables are different from one another and so immediately we know that their probabalistic behaviour must be different, despite the fact that both random variables summarize the same statistical experiment. We can also immediately see that the two random variables, while not equal to eachother, certainly dependent on one another: if you know that <span class="math inline">\(Y=1\)</span> then you know that <span class="math inline">\(X = 2\)</span>. If you know that <span class="math inline">\(Y = 3\)</span>, then you know that <span class="math inline">\(X \leq 6\)</span>.</p>
<p>To begin to capture the joint behaviour of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> we introduce a <strong>joint probability mass function</strong>. The joint probability mass function describes the behaviour of the <strong>joint distribution</strong>, in an otherwise analogous manner as the marginal probability mass function. That is, the joint probability mass function assigns a probability value for every pair of values that <span class="math inline">\((X,Y)\)</span> can take on. Then, once you know the joint behaviour of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, you can fully summarize the combined behaviour of the experiment.</p>
<p>TODO: Include an example of a joint PMF.</p>
<p>In practice, joint probability mass functions can be thought of as analogous to the contingency tables we previously saw. If the first variable represents the first random variable being considered, and the second variable represents the second random variable, then each cell of the contingency table assigns a probability to one of the joint events that could be observed in the experiment. Joint distributions are a useful generalization of contingency tables as they allow us to compactly represent not only two different random variables, but sometimes many more. All of the definitions used for the case of two random variables extend naturally to three, four, and beyond.</p>
<p>TODO: Include example of contingency table and joint PMF.</p>
<p>If we continue to consider the case of a bivariate (two variable) joint distribution, we can use this setting to introduce the concept of independence of random variables. Recall that the joint probability mass function of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is a function, <span class="math inline">\(p(x,y) = P(X = x, Y = y)\)</span>. We have also introduced the marginal mass functions, <span class="math inline">\(p_X(x) = P(X = x)\)</span> and <span class="math inline">\(p_Y(y) = P(Y = y)\)</span>. When dealing with events said that two events were independent if their joint probability was equal to the product of their marginal probabilities, that is <span class="math inline">\(P(A,B) = P(A)P(B)\)</span>.</p>
<p>If we imagine taking <span class="math inline">\(A=\{X=x\}\)</span> and <span class="math inline">\(B=\{Y=y\}\)</span>, then if <span class="math inline">\(A\perp B\)</span> we can write <span class="math inline">\(p(x,y)=p_X(x)p_Y(y)\)</span>. If this holds for every possible <span class="math inline">\(x\)</span> and every possible <span class="math inline">\(y\)</span>, then we say that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent random variables, and we write <span class="math inline">\(X \perp Y\)</span>. [TODO: fix this statement to use <span class="math inline">\(x'\)</span> and <span class="math inline">\(y'\)</span>]</p>
<p>In words, two random variables are independent whenever all possible combinations of events between them are independent. When this happens we can write that <span class="math display">\[p(x,y) = p_X(x)p_Y(y),\]</span> which is to say that the joint probability mass function is the product of the two marginal probability mass functions.</p>
<p>TODO: iinclude example regarding independence of PMFs.</p>
<p>There is an equivalence between the described definition, and a slightly more intuitive definition for independence. Whenever <span class="math inline">\(X\perp Y\)</span> we can say that any two events corresponding to <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, say <span class="math inline">\(X \in A\)</span> and <span class="math inline">\(Y \in B\)</span> are independent. The subtle distinction is that in our previous definition, we were only concerned with simple events of the form <span class="math inline">\(X=x'\)</span>, whereas here we allow any two arbtirary events. However, note that if we have the above definition holding for simple events, then <span class="math display">\[\begin{align*}
P(X \in A, Y \in B) &amp;= \sum_{x\in A}P(X=x,Y\in B) \\
&amp;= \sum_{x\in A}\sum_{y \in B} P(X=x,Y=y)\\
&amp;= \sum_{x\in A}\sum_{y \in B} p_X(x)p_Y(y) \\
&amp;= \left(\sum_{x\in A}p_X(x)\right)\left(\sum_{y\in B}p_Y(y)\right)\\
&amp;= P(X\in A)P(Y\in B).
\end{align*}\]</span> That is, even by only making the assumption for simple events, the conclusionregarding compound events follows naturally. Whenever any two random variables are known to be independent we know that any two events corrresponding to these random variables will be independent. Moreover, we can directly write down the joint probability mass function , simply by taking the product of the two marginals.</p>
<p>TODO: include example of independent functions.</p>
<p>When introducing events, we discussed how the concepts of independence and dependence could be understood more intuitively through the use of conditional probabilities. The same is true for random variables. The conditional distribution of a random variable captures the behaviour of a random variable when we have information about another. The conditional probability mass function will output the probability associated with any conditional event between multiple random variables. That is, if we wanted to characterize events of the form <span class="math inline">\(X\)</span> given <span class="math inline">\(Y=y\)</span>, which is to say <span class="math inline">\(P(X=x|Y=y)\)</span>, then we would use the conditional probability mass function of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y\)</span>, <span class="math display">\[p_{X|Y}(x|y) = \frac{p_{X,Y}(x,y)}{p_Y(y)}.\]</span></p>
<p>This definition is analogous to the formula for conditional probabilities more generally, taking the joint over the marginal. To then determine the probability of any event (for <span class="math inline">\(X\)</span>) given some information about <span class="math inline">\(Y\)</span>, you simply plug in <span class="math inline">\(X=x\)</span> and <span class="math inline">\(Y=y\)</span> into the conditional probability mass function. If you want to condition on more than one random variable, the quantities extend in exactly the same way, where for instance <span class="math display">\[P(X=x|Y=y,Z=z)=\frac{P(X=x,Y=y,z=z)}{P(Y=y,Z=z)}.\]</span></p>
<p>TODO: include example of condition al pmf</p>
<p>As was discussed, the joint probability mass function of two random variables is given by the product of the margianls whenever those variables are independent. If we take <span class="math inline">\(X\perp Y\)</span>, then plugging <span class="math inline">\(p_{X,Y}(x,y) = p_{X}(x)p_{Y}(y)\)</span> in to the expression for the conditional probability mass function gives <span class="math inline">\(p_{X|Y}(x|y) = p_X(x)\)</span>. That is, whenever two variables are independent, the conditional probability mass function is exactly equal to the marginal probability mass function. We saw that this was true for events, and the same reasoning applies here. This result gives a more intuitive method for interpretting the independence of random variables. Two random variables are independent whenever any information about the one does not provide information about theother, which is to say when they are completely uninformative for one another. With this intuitive concept in mind, it becomes easier to infer when independence of random variables seems reasonable, which becomes a useful skill for manipulating probability expressions.</p>
<p>TODO: includeexamples for independence.</p>
<p>Seeing as the joint, marginal, and conditional probability mass functions are exactly analogous to the corresponding concepts when they were introduced regarding events, it is reasonable to assume that we canextend the multiplication rule, the law of total probability, and Bayes’ theorem to the framework of probability functions as well. Indeed, each of these relationships continues to hold for random variables in much the way that would be exptected.</p>
<p>The multiplication rule simply states that <span class="math inline">\(p_{X,Y}(x,y) = p_{X|Y}(x|Y)p_Y(y) = p_{Y|X}(y|x)p_X(x)\)</span>. This can be seen by rearranging the relationship defining the conditional probabilities. Bayes’ Theorem also can be extended in nearly an identical fashion giving <span class="math display">\[p_{Y|X}(y|x) = \frac{p_{X|Y}(x|y)p_Y(y)}{p_X(x)}.\]</span> These rules give the ability to compute the joint distribution and the other conditional information, when we have information regarding some of the marginals andsome of the conditionals. These properties are used less explicitly when dealing with probability mass functions directly, instead becoming absorbed into the fabric of thedefining relationships themselves. That is to say, you are less likely to see Bayes’ theorem invoked directly when moving ebtween conditional distributions, however, moving between conditional distributions is an important skill which is very often required.</p>
<p>TODO: include examples for multiplication rule and Bayes’ theorem</p>
<p>Unlike the multiplication rule and Bayes’ theorem, the extension of the law of total probability is frequently cited when manipulating probability mass functions. It is a process which is important enough so as to warrant its own name: <strong>marginalization</strong>. The idea with marginalization is that we are going to take a joint probability mass function and <strong>marginalize</strong> it, turning it into a marginal distribution. This is analogous to the law of total probability. Note that when dealing with a random variable, <span class="math inline">\(Y\)</span>, there is some set of numeric values that <span class="math inline">\(Y\)</span> can take on. Suppose that wwe refer to these values as <span class="math inline">\(\mathcal{Y}\)</span>. A natural partition of the space is to then take each possible value for <span class="math inline">\(Y\)</span> as the event, and simply enumerate through the elements of <span class="math inline">\(\mathcal{Y}\)</span>.</p>
<p>Using this partition, we can ask about the ways that <span class="math inline">\(X\)</span> can take on any particular value. In order for <span class="math inline">\(X\)</span> to be <span class="math inline">\(x\)</span>, we know that one of the <span class="math inline">\(Y=y'\)</span> for some <span class="math inline">\(y'\in\mathcal{Y}\)</span> must have ocurred. Thus, if we add up all the possible combinations, <span class="math inline">\((X=x,Y=y_1)\)</span>, <span class="math inline">\((X=x,Y=y_2)\)</span>, and so forth, then we will have covered every possible way of making <span class="math inline">\(X=x\)</span>. This is the exact same process we used when looking at contigency tables, where we summed a row or column to get the marginal probabilities.</p>
<p>TODO: include partition graphic</p>
<p>Taking this argument and encoding it with mathematical notation we get that <span class="math display">\[P(X=x) = \sum_{y\in\mathcal{Y}} P(X=x, Y=y) \implies p_X(x) = \sum_{y\in\mathcal{Y}} p_{X,Y}(x,y).\]</span> That is, the process of marginalization involves summing over one of the random variables in a joint distribution function, leaving behind only the marginal. This is often a very effective way of determining a marginal distribution when information about two random variables is easy to disceren than information about only one.</p>
<p>To complete the analogy to the law of total probability, recall that the multiplication rule tells us that <span class="math inline">\(p_{X,Y}(x,y) = p_{X|Y}(x|y)p_Y(y)\)</span>, and so we may alsomarginalize by taking <span class="math display">\[p_X(x) = \sum_{y\in\mathcal{Y}} p_{X|Y}(x|y)p_Y(y).\]</span> This makes it clear that marginalization is often accomplished via arguments based on conditioning.</p>
<p>When confronted with questions from statistics and probability, it will often be the case that the natural answer to the question is <code>it depends.'' For instance, if asked</code>what si the probability that a student passes their next exam?’’ the likely response is `<code>it  depends.'' One very useful technique for solving these questions in a satisfactory way is to continue that line of thought and explicitly specify</code>on what.’’ For the students, for instance, you may say <code>it depends  on how much they study.'' The conceit in this situation is that, if you were to know how much the student has studied, then you would better understand the outcomes of the student's test. In our mathematical terms this means you have a firm belief about the conditional distribution  between the random quantities of exam performance  and study time. The process of marginalization, and the law of total  probability before that, provide useful ways of being able to translate these</code>it depends’’ statements into concrete beliefs about the marginal probabilities. Recall that marginal distributions are distributions which do not depend on any otherquantitity, and instead, thy capture the overall behaviour. They have, in some sense, averaged out all other factors and give you the beliefs which do not depend on anything else at all. The technique for accomplishing this is marginalization, and other forms of conditioning arguments.</p>
<p>TODO: include worked example on conditioning.</p>
<section id="independent-and-identically-distributed-a-framework-for-interpretation" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="independent-and-identically-distributed-a-framework-for-interpretation"><span class="header-section-number">5.1</span> Independent and Identically Distributed: A Framework for Interpretation</h2>
<p>A very common assumption when addressing questions in statistics and in probability is that we have a set of random variables which are independent and identically distributed (iid). We now have the tools to understand concretely what this means. Specifically, a set of random variables, <span class="math inline">\(X_1,X_2,\dots,X_n\)</span> are said to be independent and identically distributted (denoted iid almost all the time) whenever (i) every subset of random variables in the collection is independent of every other subset of random variables in the collection, and (ii) the marginal distribution for each of the random variables are exactly the same. The assumption of iid random quantities will often come up when we are repeating a process many times over, and thinking about what observations will arise from this. Suppose that <span class="math inline">\(X_1\)</span> is a random variable that takes the value <span class="math inline">\(1\)</span> if a flipped coin comes up heads, and <span class="math inline">\(0\)</span> otherwise. If we imagine flipping this coin <span class="math inline">\(100\)</span> times then it is reasonable to assume that each sequential coin flip will be independent of eacch other coin flip, since the result on one flip of a coin should not influence the result of any other flip of a coin. Moreover, every time the coin is flipped, it is reasonable to assume that the probability it shows up heads remains the same. As a result, these <span class="math inline">\(100\)</span> random quantities, <span class="math inline">\(X_1,  X-2,  \dots,  X_{100}\)</span> can be said to be iid.</p>
<p>TODO: include other iid examples</p>
<p>While we will use the assumption of iid random variables later, they also provide an intuitive method for interpretting probability functions and distributions. Suppose that we wwere to take a distribution function, <span class="math inline">\(p_X(x)\)</span>. If we were able to generate independent and identically distributed realizations from this probability mass ufnction, then the function <span class="math inline">\(p_X(x)\)</span> describes the behaviour for these repeated realizations. Specifically, <span class="math inline">\(p(x)\)</span> will give the long-run proportion of realizations of the iid random variables which take the value <span class="math inline">\(x\)</span>.</p>
<p>TODO: Include interpretation statement</p>
<p>This type of statement is always the flavour of interpretation statements that are made with respect to probability and statistics. It will always be the case that, in order to understand what is meant specifically by a statement of probability will involve the repetition of some statistical experiment over and over again. When we were discussing sample spaces and experiments directly, we talked about repeating the experiment over and over again. When we begin to work with random variables instead, it becomes more natural to think about the replication procedures coming through the use of independent and identically distributed random variablles.</p>
<p>As the study of probability foes on, we begin to need to work with random quantities in a strictly theoretical sense. In introductory level problems, we are often holding in mind very concrete examples to illustrate the procedures and concepts. In this setting it is easy enough to hold in mind the experiment of interest: for instance, we may have a random variable representing the result of a coin toss, and you can envision repeatedly tossing a coin. As the concepts become less concrete, more abstract, and harder to draw directl parallels to tangible scenarios, it becomes more and more important to rely on the interpretations rooted in a series of independent and identically distributed random variables. A large component of statistics as an area of study is making explicit the assumptions we are working with, and doing our best to ensure that these are reasonable. By interpreting probability mass functions as the proportion of independent and identically distributed random variables that take on a particular value, when we repeatedly take realizations of these random variables ad infinitum, this philosophy is made clear and explicit.</p>
</section>
<section id="expectation" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="expectation"><span class="header-section-number">5.2</span> Expectation</h2>
<p>Until this point in our discussions of probability we have relied upon characterizing the behaviour of a random variable via the use of probability mass functions. In some sense, a probability mass function captures all of the probabilistic behaviour of a discrete random variable. Using the mass function you are able to characterize how often, in the long-run, any particular value will be observed, and any questions associated with this. As a result, the mass function remains a critical area of focus for understanding how random quantities behave.</p>
<p>However, these functions need to be explored and manipulated in order for useful information to be extracted from them. They do not summarize this behaviour effectively, as they are not intended to be a summary tool, and understandably we often wish to have better numeric quantities which are able to concisely indicate components of the behaviour of a distribution. Put differently, provided with a priobability mass function it is hard to immediately answer ``what do we expect to happen, with this random variable?’’ despite the fact that this is a very obvious first question.</p>
<p>To address questions related to expectations, we turn towards the statistical concept of an <strong>expected value</strong>. We refer to expected values as expectations, averages, and means of a distribution, interchangeably. The idea with an expected value is that we are trying to capture, with one single number, what value is expected when we make observations from the random quantity. There are many ways one might think to describe our expectations, and it is worth exploring these concepts in some detail.</p>
<p>One way that we may think to define our expected value is by asking what value is the most probable. This is a question which can be directly answered using the probability mass function. The process for this would require looking at the function and determining which value for <span class="math inline">\(x\)</span> corresponds to the highest probability: this is the value that we are most likely to see. Sometimes this procedure is fairly straightforward, sometimes it is quite complicated. No matter the complexity of the specific situation, the underlying process is the same: what value has the highest probability of being seen, and that is the most likely one.</p>
<p>TODO: Example of mode</p>
<p>As intuitive as this may seem, this is not the value that will be used as the expectedvalue generally. Instead, this quantity is referred to as the <strong>mode</strong>. While the mode is a useful quantity, and for some decisions will be the most pertinent summary value, there are some major issues with it as a general measure which make it less desirable. For starters, consider that our most common probability model considered until this point has been that of equally likely outcomes. Here, there is no well-defined mode (convention tends to be taking it as the set of all the most probable values). Presenting the mode is equivalent to presenting the full mass function in this setting.</p>
<p>While the case of equally likely outcomes is a fairly strong explanation for some issues with the mode, it need not be so dramatic to undermine its utility. It is possible for a distribution to have several modes which are quite distinct from one another, even if it’s not all values. Moreover, it is quite common for the modal value to be not particularly likely itself. Consider a random variable that can take on a million different values. If all of the probabilities are approximately <span class="math inline">\(0.000001\)</span> then presenting the mode as the most probable value does not translate to saying that the mode is particularly probable.</p>
<p>TODO: incllude example where the mode is slightly more likeely than a string of similar values.</p>
<p>If the mode has these shortcomings, what else might work? Another intuitive concept is to try to select the ``middle’’ oof thedistribution. One way to define the middle would be to select the value such that half of observations are beneath it, and half of observations are above it. That way, when you are told this value, you immediately know that it is equally likely to observe values on either side of this mark. This is also a particularly intuitive definition for expected value, and is important enough to be named: <strong>the median</strong>.</p>
<p>The median is the midpoint of a distribution, and is very important for describing the behaviour of random ariables. Medians are often the most helpful single value to report to indicate the typical behaviour of a distribution, and they are frequently used. When people interpret averages, in general, it is often the median that they are actually interpretting. It is very intuitive to be given a value and know that it is the middle of all the possible values for a distribution.</p>
<p>TODO: include examples on medians</p>
<p>Despite the advantages of medians, they have their own drawbacks as well. For starters, the median can be exceptionally challenging to compute in certain settings. As a result, even when a median is appropriate, it may not be desirable if it is too challenging to determine. Beyond the difficulties in computation, medians have some properties which may be undesirable, depending on the specific use case. One concern which arises frequently is that medians are not translated to totals, which can make them challenging in certain use cases.</p>
<p>Suppose that you are a store and you know that your median quantity of items sold in a day is <span class="math inline">\(50\)</span> and the median cost of these items is <span class="math inline">\(\$10\)</span>, you cannot simply multiply the <span class="math inline">\(50\)</span> and the <span class="math inline">\(\$10\)</span> to suggest that your median revenue in a day is <span class="math inline">\(\$500\)</span>. Doing this ttype of unit conversion or basic arithmetic with medians can be challenging, and as a result they are not always the most useful when reporting values that are going to be interpretted as rates.</p>
<p>TODO: Expand on the above example.</p>
<p>Beyond the basic manipulation medians have a feature which is simultaneously a major benefit in some settings, and a major fallback in others. Specifically, medians are less influenced by extreme values in the probability distribution. Consider two different distributions: one of them is equally likely to take any value between <span class="math inline">\(1\)</span> and <span class="math inline">\(10\)</span>, where the other is equally likely to take any value between <span class="math inline">\(1\)</span> and <span class="math inline">\(9\)</span> or <span class="math inline">\(1,000,000\)</span>. In both of these settings, we can take the median to be <span class="math inline">\(5.5\)</span> since half of the probability mass falls above <span class="math inline">\(5.5\)</span> and half falls below it.</p>
<p>The median, in some sense, ignores the extreme value in the probability distribution and remains stable throughout it. In certain settings, this can be very desirable. For instance, in the distribution of household incomes, the median may be an appropriate measure seeing as there are a few families who have very extreme incomes which otherwise distort the picture provided by most families. In this sense, the median’s robustness to extreme values is a positive feature of it in terms of a summary measure for distributional behaviour.</p>
<p>Suppose instead that you work for an insurance company and are concerned with understanding the value of insurance claims that your company will need to pay out. Thedistribution will look quite similar to the income distribution: most of the probability will be assigned to fairly small claims, with a small chance of a very large one. As an insurance company, if you use the median this large claim behaviour will be smoothed over, perhaps leaving you unprepared for the possibility of extremely large payouts. In this setting, the extreme values are informative and important, and as a result the median’s robustness becomes a hindrance to correctly describing the behaviour.</p>
<p>TODO: Another median example?</p>
<p>Between the median and the mode we have two measures which capture some sense of expected value, each with their own set of strengths and drawbacks. Neithercapture what it is that is referred to as <em>the</em> expected value. For this, we need to take inspiration from the median, and consider another way that we may think to find the center of the distribution.</p>
<p>If the median gives the middle reading along the values sequentially, we may also wish to think about trying to find the ``center of gravity’’ of the numbers. Suppose you take a pen, or marker, or small box of chocolates, and you wish to balance this object on a finger or an arm. To do so, you do not place the item so that half of it sits on one side of the appendage and half on the other: you adjust the location so that half of the masssits on either side of the appendage.</p>
<p>Throughout our probability discussions, we have always referred to probability as mass itself. We use the probability mass function to generate our probability values. This metaphor can be extneded when we try to find the center of the distribution. If we imagine placing a mass with weight equal to the probability mass functions value at each value that a random variable can take on, we may ask: where would we have to place a fulcrum to have this number line be balanced? The answer to this question serves as another possible measure of center.</p>
<p>It turns out that this notion of center is the one that we are all most familiar with: the simple average. And this simple average is also the conception of expectation which gets bestowed with the name ``expected value’’. Mathematically, the expeccted value is desirable for many reasons, some of which we will study in more depth later on. One of these desirable features, which stands in contrast with the median, is the comparative ease with which expected values can be computed. For a random variable, <span class="math inline">\(X\)</span>, we write the expected value of <span class="math inline">\(X\)</span> as <span class="math inline">\(E[X]\)</span>, and assume that <span class="math inline">\(X\)</span> takes values in <span class="math inline">\(\mathcal{X}\)</span> with a probability mass function <span class="math inline">\(p_X(x)\)</span>, we get <span class="math display">\[E[X] = \sum_{x \in \mathcal{X}} xp_X(x).\]</span></p>
<p>TODO: Example compute simple expected value.</p>
<p>In the case of an equally likely probability model, the expected value becomes the standard average that is widely used. Suppose that there are <span class="math inline">\(n\)</span> options in the sample space, denoted <span class="math inline">\(x_1,\dots,x_n\)</span>, then we can write <span class="math display">\[E[X] = \sum_{i=1}^n x_i\frac{1}{n} = \frac{1}{n}\sum_{i=1}^nx_i.\]</span> When the probability models are more complex, the formula is not precisely the stnadard average - instead, it becomes a weighted average.</p>
<p>TODO: Add basic average example.</p>
<p>While less commonly applied than the simple average, a weighted average is familiar to most students for a crucial purpose: grade calculations. If you view the weight of each item in a course as a probability mass, and the grade you scored as the value, then your final grade in the course is exactly the expected value of this distribution. The frequency with which expectedvalues are used make them attractive as a quick summary for the center of a distribution.</p>
<p>TODO: Include pricing calculation showing mean versus median.</p>
<p>While the mean provides a useful, intuitive measure of center of the distribution, it is perhaps counter intuitive to name it the expected value. To understand the naming convention it is easiest to consider the application which has likely spurred more development of statistics and probability than any other: gambling.</p>
<p>Suppose that there is some game of chance that can pay out different amounts with different probabilities. A critical question for a gambler in deciding whether or not to play such a game is ``how much can I expect to earn, if I play?’’ This is crucial to understanding, for instance, how much you should be willing to pay to participate, or if you are the one running the game, how much you should charge to ensure that you make a profit.</p>
<p>If you want to understand what you expect to earn, the intuitive way of accomplishing this is to weight each possible outcome by how likely it is to occur. This is exactly the expected value formula that has been provided, and so the expected value can be thought of as the expected payout of a game of chance where the outcomes are payouts corresponding to each probability.</p>
<p>TODO: Include expected payout calculation.</p>
<p>This also represents the cost at which a rational actor should be willing to pay to participate. If a game ofchance costs more than the expected value to play, in the long run you will lose money. If a game of chance costs less than the expected value, in the long run you will earn money. It is hard to overstate the utility of gambling in developing probabiility theory, and as such these types of connections are expected.</p>
<p>To interpret the expected value of a random variable, one possibility is using the intuition that we used to derive the result. Notably, the expected value is the center of mass of the distribution, where the masses correspond to probabilities. This means that it is not necessarily an actual central number over the range, but rather that it sits in the weighted middle. While this interpretation is useful in many situations, there are times where the point of balance is a less intuitive description. For these, it can sometimes be useful to frame the expected value as the long-term simple average from the distribution.</p>
<p>If we imagine observing many independent and identically distributed random variables, then as the number of samples tends to infinity, the expected value of <span class="math inline">\(X\)</span> and the simple average will begin to coincide with one another. That is the distance between <span class="math inline">\(E[X]\)</span> and <span class="math inline">\(\frac{1}{n}\sum_{i=1}^n X_i\)</span> will shrink to <span class="math inline">\(0\)</span>. As a result, we can view the expected value as the average over repeated experiments. This interpretation coincides nicely with the description based on games of chance. Specifically, if you were to repeatedly play the same game of chance, the average payout per game will be equal to the expected value, if you play for long enough.</p>
<p>TODO: Include convergence graphic.</p>
<p>Somtimes the value of a random variablle needs to be mapped through a function to give the value which is most relevant to us. Consider, for instance, a situation wherein the side lengths of boxes being manufactured by a specific supplier are random, due to incorrectly calibrated tolerances in the machines. The resulting boxes are cubes, but what is of more interest is the volume of the produced box, not the side length. If a box has side length <span class="math inline">\(x\)</span>, then its volume will be <span class="math inline">\(x^3\)</span>, and so we may desire some way of computing <span class="math inline">\(E[X^3]\)</span> rather than <span class="math inline">\(E[X]\)</span>.</p>
<p>In general, for some function <span class="math inline">\(g(X)\)</span>, we may want to compute <span class="math inline">\(E[g(X)]\)</span>. It is important to recognize that, generally speaking, <span class="math inline">\(E[g(X)] \neq g(E[X])\)</span>. This is a common mistake, and an attractive one, but a mistake nonetheless. If we are unable to simply apply the function to the epxected value, then the question of how to compute the expected value remains. Instead of applying the function to overall expected value, instead, we simply apply the function to each value in the defining relationship for the expected value. That is, <span class="math display">\[E[g(X)] = \sum_{x\in\mathcal{X}} g(x)p_X(x).\]</span> This is sometimes referred to as the ``law of the unconscious statistician,’’ a name which may be aggressive enough to help remember the correct way to compute the expectation.</p>
<p>TODO: Move the next thing up. Where the median demonstrated robustness against extreme values in the distribution, the mean (or expected value) does not. For instance, if we consider the distribution of incomes across a particular region, the mean will be much higher than the median, as those families with exceptionally high incomes will not be smoothed over as they were with medians. In this case, the lack of robustness for the expected value will render the mean a less representative summary for the true behaviour of the random quantity.</p>
<p>To see this concretely, consider the difference between a random variable which with equal probability takes a value between <span class="math inline">\(1\)</span> and <span class="math inline">\(10\)</span>. This will have <span class="math inline">\(E[X] = 5.5\)</span>. Now, if the <span class="math inline">\(10\)</span> is made to be <span class="math inline">\(1,000,000\)</span>, the expected value will now be <span class="math inline">\(E[X] = 100,004.5\)</span>. This is a far cry from the median which does not change from <span class="math inline">\(5.5\)</span> in either case. This lack of robustness is desirable in the event of the insurance example from the median discussion, but will be less desirable in other settings.</p>
<p>The mean, median, and mode are the three standard measures of central tendency. They are also referred to as measures of location, and in general, are single values which describe the standard behaviour of a random quantity. Each of the three has merits as a measure, and each has drawbacks for certain settings. The question of which to use and when depends primarily on the question of interest underconsideration, rather than on features of the data alone. Often, presenting more than one measure can give a better sense of the distributional behaviour that any one individual will.</p>
<p>TODO: Include example of choosing measures.</p>
<p>Despite the utility of all three measures, the expected value holds a place of more central importance in probability and statistics. A lot of this has to do with further mathematical properties of the mean. Because of its central role, it is worth studying the expected value in some more depth. % END OF MOVING SECTION.</p>
<p>TODO: include example using LOTUS.</p>
<p>These functions applied to random variables are often thought of as ``transformations’’ of the random quantities. For instance, we <em>transformed</em> a side length into a volume. While the law of the unconscious statistician will apply to any transformation for a random variable, we can sometimes use shortcuts to circumvent its application. In particular, when <span class="math inline">\(g(X) = aX + b\)</span>, for constant numbers <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, we can greatly simplify the expected value of the transformation. To see this note <span class="math display">\[\begin{align*}
E[aX + b] &amp;= \sum_{x\in\mathcal{X}}(ax + b)p_X(x) \\
&amp;= \sum_{x\in\mathcal{X}}axp_X(x) + bp_X(x) \\
&amp;= a\sum_{x\in\mathcal{X}}xp_X(x) + b\sum_{x\in\mathcal{X}}p_X(X) \\
&amp;= aE[X] + b.
\end{align*}\]</span> That is, in general, we have that <span class="math inline">\(E[aX + b] = aE[X] + b\)</span>.</p>
<p>This is particularly useful as linear transformations like <span class="math inline">\(aX+b\)</span> arise very commonly. For instance, most unit conversions are simple linear combinations. If a random quantity is measured in one unit then this result can be used to quickly convert expectations to another.</p>
<p>TODO: include example of temperature or weight conversion.</p>
<p>This type of linear transformation also frequently comes up with games of chance and payouts, or with scoring more generally. For instance, suppose you are betting a certain amount on the results of a coin toss, or that you are taking a multiple choice test that gives <span class="math inline">\(2\)</span> points for a correct answer.</p>
<p>Measures of central tendency are important to summarize the beahviour of a random quantity. Whether using the mean, median, or mode, these measures of location describe, on average, what to expect from observations of the random quantity. However, understanding a distribution requires understanding far more than simply the measures of location. As was discussed previously, the probability mass function captures the complete probabilistic behaviourof a discrete random variable, it is only intuitive that some information would be lost with a single numeric summary.</p>
<p>TODO: Example with equivalent mean, median, and mode.</p>
<p>A key characteristic of the behaviour of a random variable which is not captured by the measures of location is the variability of the quantity. If we imagine taking repeated realizations of a random variable, the variability of the random variable captures how much movement there will be observation to observation. If a random variable has low variability, we expect that the various observations will cluster together, becoming not too distant from one another. If a random variable has high variability, we expect the observations to jump around each time.</p>
<p>Just as was the case with measures of location, there are several measures of variability which may be applicable in any given setting. One fairly basic measure of the spread of a random variable is simply the range of possible values: whati s the highest possible value, what is the lowest possible value, and how much distance is there between those two points? This is a fairly intuitive notion, and is particularly useful in the equal probability model over a sequence of numbers. Consider, for instance, dice. dice are typically defined by the range of values that they occupy, say <span class="math inline">\(1\)</span> to <span class="math inline">\(6\)</span>, or <span class="math inline">\(1\)</span> to <span class="math inline">\(20\)</span>. Once you know the values present on any die, you have a sense for how much the values can move observation to observation.</p>
<p>TODO: Include example for the range.</p>
<p>While the range is an important measure to consider to determine the behaviour of a random variable, it is a fairly crude measurement. It may be the case that, while the extreme values are possible, they are sufficiently unlikely so as to come up very infrequently and not remain representative of thelikely spread of observations. Alternative, many random variables have a theoretically infinite range. In these cases, providing the range will likely not provide much utility.</p>
<p>TODO: Include example.</p>
<p>To rememdy these two issues, we can think of some techniques for modifying the range. Instead of taking the start and end points to be the lowest and highest values, we can instead consider ranges of values which remain more plausible. A common way to do this is to extend our concept of a median beyond the half-way point. The median of a random variable <span class="math inline">\(X\)</span>, is the value, <span class="math inline">\(m\)</span>, such that <span class="math inline">\(P(X \leq m) = 0.5\)</span>. While there is good reason to care about the midpoint, we can think of generalizing this to be <em>any</em> probability.</p>
<p>That is, we could find a number <span class="math inline">\(z\)</span>, such that <span class="math inline">\(P(X \leq z) = 0.1\)</span>. We could then use this value to conclude that <span class="math inline">\(10\%\)</span> of observations are below <span class="math inline">\(z\)</span>, and <span class="math inline">\(90\%\)</span> of observations are above <span class="math inline">\(z\)</span>. (TODO: Change this to be ``probability of observation’’). These values are referred to, generally, as percentiles and they are the natural extension of medians. We will typically denote the <span class="math inline">\(100p\)</span>th percentile as <span class="math inline">\(\zeta(p)\)</span>, which is the value <span class="math inline">\(P(X \leq \zeta(p)) = p\)</span>. Thus, the median of a distribution is <span class="math inline">\(\zeta(0.5)\)</span>.</p>
<p>TODO: Include examples</p>
<p>We can leverage percentiles to remedy some of the issues with the range as a measure of variability. Framed in terms of percentiles, the minimum value is <span class="math inline">\(\zeta(0)\)</span>, and the maximum value is <span class="math inline">\(\zeta(1)\)</span>. Instead of considering theextreme endpoints, if we consider the difference between more moderate percentiles, we can overcome the major concenrs outlined with the range. The most common choices would be to take <span class="math inline">\(\zeta(0.25)\)</span> and <span class="math inline">\(\zeta(0.75)\)</span>; these are referred to as the first and third quartiles, respectively. They are named as, taking <span class="math inline">\(\zeta(0.25)\)</span>, <span class="math inline">\(\zeta(0.5)\)</span> and <span class="math inline">\(\zeta(0.75)\)</span>, the distribution is cut into quarters.</p>
<p>TODO: Include examples.</p>
<p>With the first and third quartiles computed, we can compute the interquartile range, which is given by <span class="math inline">\(\zeta(0.75)-\zeta(0.25)\)</span>. Typically, we denote the interquarite range simply as <span class="math inline">\(\text{IQR}\)</span>, and like the overall range, it gives a measure of how much spread there tends to be in the data. Unlike the range, however, we can be more certain that both the first and third quartiles are reasonable values around which repeated observations of the random variable would be observed. Specifically, there is a oribability of <span class="math inline">\(0.5\)</span> that a value between the first and third quartile will be observed. The larger the <span class="math inline">\(\text{IQR}\)</span>, the more spread out these moderate observations will be, and as a result, the more variable the distribution is.</p>
<p>TODO: Write examples.</p>
<p>Both the range and the interquartile range give a sense of the variation in the distribution irrespective of the measures of location for that distribution. Another plausible method for assessing the variability of a distribution is to assess how far we expect observations to be from the cneter. Intuitively, if observations of <span class="math inline">\(X\)</span> are near the center with high probability, then the distribution will be less variable than if the averagedistance to the center is larger.</p>
<p>This intuitive measure of variability is useful for capturing the behaviour of a random variable, particularly when paired iwth a measure of location. However, we do have to be careful: not all measures of dispersion based on this notion will be useful. Consider the most basic possibility, to consider <span class="math inline">\(X - E[X]\)</span>. We might ask, for instance, what is the expected value of this quantity. If we take <span class="math inline">\(E[X - E[X]]\)</span> then note that this a linear combination in expectation since <span class="math inline">\(E[X]\)</span> is just some number. Thus, <span class="math inline">\(E[X-E[X]] = E[X] - E[X] = 0\)</span>. In other words, the expected difference between a random variable and its mean is exactly <span class="math inline">\(0\)</span>. We thus need to think harder about how best to turn this intuition into a useful measure of spread as the first idea will result in <span class="math inline">\(0\)</span> for all random quantities.</p>
<p>The issue with this procedure is that some realizations are going to be below the mean, making the difference negative, and some will be above the mean, making the difference positive. Our defining relationship for the mean relied on balancing these two sets of mass. However, when discussing the variability of the random variable, we do not much care whether the observations are lower than expected or higher than expected, we simply care how much variability there is around what is expected. To remedy this, we should consider only the distance between the observation and the expectation, not the sign. That is, if <span class="math inline">\(X\)</span> is <span class="math inline">\(5\)</span> below <span class="math inline">\(E[X]\)</span> we should treat that the same as if <span class="math inline">\(X\)</span> is <span class="math inline">\(5\)</span> above <span class="math inline">\(E[X]\)</span>.</p>
<p>There are two common ways to turn value into its magnitude in mathematics generally: squaring the number and using absolute values. Both of these tactics are useful approaches to defining measures of spread, and they result in the <strong>variance</strong> when using the expected value of the squared deviations, and the <strong>mean absolute deviation</strong> when using the absolute value. While <span class="math inline">\(E[|X-E[X]|]\)</span> is perhaps the more intuitive quantity to consider, generally speaking it will not be the one that we use.</p>
<p>In general when we need a positive quantity in mathematics it will typically be preferable to consider the square to the absolute value. The reasons for this are plentiful, but generally squares are easier to handle than absolute values, and as a result become more natural quantities to handle. The variance is the central measure of deviation for random variables, so much so that we give it its own notation, <span class="math display">\[\text{var}(X) = E[(X-E[X])^2].\]</span></p>
<p>Note that if we take <span class="math inline">\(g(X) = (X-E[X])^2\)</span>, then the variance of <span class="math inline">\(X\)</span> is the expected value of a transformation. We have seen that to compute these we apply the law of the unconscious statistician, and substitute <span class="math inline">\(g(X)\)</span> into the defining relationship for the expected value, which for the variance gives <span class="math display">\[\text{var}(X) = \sum_{x\in\in\mathcal{X}} (x-E[X])^2p_X(x).\]</span> Prior to computing the variance, we must first work out the mean as the function <span class="math inline">\(g(X)\)</span> relies upon this value.</p>
<p>TODO: Include example for calculating variance.</p>
<p>The higher that an individual random variables variance is, the more spread we expect there to be in repeatedly realizations of that quantity. Specifically, the more spread out around the mean value the random variable will be. A random variable with a low variance will concentrate more around the mean value than one with a higher variance. One confusing part of the variance of a random variable is in trying to assess the units. Suppose that a random quantity is measured in a particular set of units - dollars, seconds, grams, or similar. In this case, our interpretations of measures of location will all be in the same units, which aids in drawing connections to the underlying phenomenon that we are trying to study. However, because the variance is squared, we cannot make the same extensions to it: variance is not measured in the regular units, but in the regular units squared.</p>
<p>Suppose you have a random time being measured, perhaps the reaction time for some treatment to take effect in a treated patient. Finding the mean or median will give you a result that you can read off in seconds as well. The range and interquartile range both give you the spread in seconds. However, if you work out the variance of this quantity it will be measured in seconds squared - a unit that is challenging to have much intuition about. To remedy this we will often use a transformed version of the variance, called the <strong>standard deviation</strong>, returning the units to be only the original scale. The standard deviation of a random variable is simply given by the square root of the variance, which is to say <span class="math display">\[\text{SD}(X) = \sqrt{\text{var}(X)}.\]</span> We do not often consider computing the standard deviation directly, and so will most commonly refer to the variance when discussing the behaviour of a random variable, but it is important to be able to move seamlessly between these two measures of spread.</p>
<p>TODO: Standard deviation.</p>
<p>When computing the variance of a random qauntity, we often use a shortcut for the formula. Consider <span class="math display">\[\begin{align*}
\text{var}(X) &amp;= \sum_{x\in\mathcal{X}} (x-E[X])^2p_X(x) \\
&amp;= \sum_{x\in\mathcal{X}} (x^2 - 2xE[X] + E[X]^2)p_X(x) \\
&amp;=\sum_{x\in\mathcal{X}} x^2p_X(x) - 2E[X]\sum_{x\in\mathcal{X}}xp_X(x) + E[X^2]\sum_{x\in\mathcal{X}}p_X(x)\\
&amp;= E[X^2] - 2E[X]E[X] + E[X]^2\\
&amp;= E[X^2] - E[X]^2.
\end{align*}\]</span></p>
<p>This result gives us the identity that the variance of <span class="math inline">\(X\)</span> can be found via <span class="math inline">\(E[X^2] - E[X]^2\)</span>. Generally, this is moderately more straightforward to calculate since <span class="math inline">\(X^2\)</span> is an easier transformation than <span class="math inline">\((X-E[X])^2\)</span>. This identity will come back time and time again, with a lot of versatility in the ways that it can be used. Typically, when a variance is needed to be calculated the process is to simply compute <span class="math inline">\(E[X]\)</span> and <span class="math inline">\(E[X^2]\)</span>, and then apply this relationship.</p>
<p>TODO: include variance calculation example.</p>
<p>With expectations, we saw that <span class="math inline">\(E[g(X)]\)</span> needed to be directly computed from the definition. The same is true for variances of transformations. Specifically, <span class="math inline">\(\text{var}(g(X))\)</span> is given by <span class="math inline">\(E[(g(X) - E[g(X)])^2]\)</span> which can be simplified with the previous relationship as <span class="math inline">\(E[g(X)^2] - E[g(X)]^2\)</span>. Just as with expectations, it is important to realize that <span class="math inline">\(\text{var}(g(X)) \neq g(\text{var}(X))\)</span>, and so dealing with transformations requires further work.</p>
<p>TODO: Transformation example. TODO: Move the following discussion up. Beyond being linear over simple transformations, summations in general behave nicely with expectations. Specifically, for any quantities separated by addition, say <span class="math inline">\(g(X) + h(X)\)</span>, the expected value will be the sum of each expected value. Formally, <span class="math display">\[\begin{align*}
E[g(X) + h(X)] &amp;= \sum_{x\in\mathcal{X}} (g(X) + h(X))p_X(x) \\
&amp;= \sum_{x\in\mathcal{X}} g(X)p_X(x) + h(x)p_X(x) %todo fix capitals\\
&amp;= \sum_{x\in\mathcal{X}} g(x)p_X(x) + \sum_{x\in\mathcal{X}} h(x)p_X(x) \\
&amp;= E[g(X)] + E[h(X)].
\end{align*}\]</span> Behaving well under linearity is one of the very nice properties of expectations. It will come in useful when dealing with a large variety of important quantities, and as we will see shortly, this linearity will also extend to multiple different random quantities.</p>
<p>TODO: add example of linearity. %End section to move.</p>
<p>With expectations, we highlighted linear transformations as a special case, with <span class="math inline">\(g(X) = aX + b\)</span>. For the variance, the linear transformations are also worth distinguishing from others. To this end, we can apply the standard identity for the variance, giving <span class="math display">\[\begin{align*}
E[(aX+b)^2] &amp;= E[a^2X^2 + 2abX + b^2] \\
&amp;= E[a^2X^2] + E[2abX] + E[b^2]\\
&amp;= a^2E[X^2] + 2abE[X] + b^2.
\end{align*}\]</span></p>
<p>TODO:Move upwards Note that part of the property of the linearity of expectation that we can immediately see if that the expected valuye of any constant is always that constant. If we take <span class="math inline">\(a = 0\)</span>, then we see that <span class="math inline">\(E[aX + b] = E[b] = b\)</span>. Thus, any time that we need to take the expected value of any constant number, we know that it is just that number. %End upwards movement</p>
<p>Next, we note that <span class="math inline">\(E[aX + b] = aE[X] + b\)</span> and so <span class="math display">\[\begin{align*}
E[aX + b]^2 &amp;= (aE[X] + b)^2 \\
&amp;= a^2E[X]^2 + 2abE[X] + b^2.\end{align*}\]</span> Differencing these two quantities gives <span class="math display">\[a^2E[X^2] + 2abE[X] + b^2 - a^2E[X]^2 - 2abE[X] - b^2 = a^2(E[X^2] - E[X]^2).\]</span> By noting that <span class="math inline">\(E[X^2] - E[X]^2\)</span>, we can complete the statement that <span class="math display">\[\text{var}(aX + b) = a^2\text{var}(X).\]</span></p>
<p>Thus, when applying a linear transformation, only the multiplicative constant matters , and it transforms the varaince by a squared factor. This should make some intuitive sense that the additive constant does not change anything. If we consider that variance is a measure of spread, adding a constant value to our random quantity will not make it more or less spread out, it will simply shift where the spread is located. This is not true of the mean, which measures where the center of the distribution is, which helps explain why the result identities are different.</p>
<p>TODO: Example using this.</p>
<p>In the same way that the linearit of expectation demonstrates that the expected value of any constant is that constant, we can use this identity to show that the variance of constant is zero. However, we can also reason to this based on our definitions so far. Suppose that we have a random variable which is constant. This seems to be an oxymoron, but it is perfectly well defined. A constant <span class="math inline">\(b\)</span> can be seen as a random variable with probability distribution <span class="math inline">\(p_X(x) = 1\)</span> if <span class="math inline">\(x=b\)</span> and <span class="math inline">\(p_X(x) = 0\)</span> otherwise. In this case, the expected value is going to be <span class="math inline">\(E[X] = 1(b) = b\)</span>, and <span class="math inline">\(E[X^2] = 1(b)^2 = b^2\)</span>. As a result, we see that <span class="math inline">\(E[b] = b\)</span>, as previously stated, and <span class="math inline">\(\text{var}(b) = E[X^2] - E[X]^2 = b^2 - b^2 = 0\)</span>. From an intuitive perspective, there is no variation around the mean of a constant: it is always the same value. As a result, when taking the variance, we know that it should be <span class="math inline">\(0\)</span>.</p>
<p>Unlike the expecctation, the variance of additive terms will not generally be the addition of the varainces themselves. That is, we cannot say that <span class="math inline">\(\text{var}(g(X) + h(X)) = \text{var}(g(X)) + \text{var}(h(X))\)</span>, as a general rule. Writing out the definition shows issue with this: <span class="math display">\[E[(g(X) + h(X))^2] = E[g(X)^2] + 2E[g(X)h(X)] + E[h(X)^2].\]</span> The first and third terms here are nicely separated and behave well. However, the central term is not going to be easy to simplify, in general. You can view <span class="math inline">\(g(X)h(X)\)</span> as a function itself, and so <span class="math inline">\(E[g(X)h(X)] \neq E[g(X)]E[h(X)],\)</span>$ in general. Instead, this will typically need to be worked out for any specific set of functions.</p>
</section>
<section id="conditional-and-joint-expectations-and-variances" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="conditional-and-joint-expectations-and-variances"><span class="header-section-number">5.3</span> Conditional and Joint Expectations and Variances</h2>
<p>Up until this point we have considered the marginal probability distribution when exploring the measures of central tendency and spread. These help to summarize the marginal behaviour of a random quantity, cpaturing the distribution of, for instance, <span class="math inline">\(X\)</span> alone. When introducing distributions, we also made a point to introduce the conditional distribution as one which is particularly relevantwhen there is extra information. The question ``what do wwe expect to happen, given that we have an additional piece of information?’’ is not only well-defined, but it is an incredibly common type of question to ask. To answer it, we require <strong>conditional expectations</strong>.</p>
<p>TODO: Include set of questions relating to conditional expectation.</p>
<p>In principle, a conditional expectation is no more challenging to calculate than a marginal expectation. Suppose we want to know teh expected value of <span class="math inline">\(X\)</span> assuming that we know that a second random quantity, <span class="math inline">\(Y\)</span> has taken on the value <span class="math inline">\(y\)</span>. We write this as <span class="math inline">\(E[X|Y=y]\)</span>, and all we do is replace <span class="math inline">\(p_X(x)\)</span> with <span class="math inline">\(p_{X|Y}(x|y)\)</span> in the defining relationship. That is <span class="math display">\[E[X|Y=y] = \sum_{x\in\mathcal{X}}xp_{X|Y}(x|y).\]</span> In a sense, we can think of the conditional distribution of <span class="math inline">\(X|Y=y\)</span> as simply being a distribution itself, and then work with that no differently. The conditional variance, which we denote <span class="math inline">\(\text{var}(X|Y=y)\)</span> is also exactly the same.</p>
<p>TODO: Include an example.</p>
<p>Above we supposed that we knew that <span class="math inline">\(Y=y\)</span>. However, sometimes we want to work with the conditional distribution more generally. That is, we want to investigate the behaviour of <span class="math inline">\(X|Y\)</span>, without yet knowing what <span class="math inline">\(Y\)</span> equals. We can use the same procedure as above, however, this time we leave <span class="math inline">\(Y\)</span> unspecified. We denote this as <span class="math inline">\(E[X|Y]\)</span>, and this expression will be (in general) a function of <span class="math inline">\(Y\)</span>. Then, whenever a value for <span class="math inline">\(Y\)</span> is observed, we can simply specify <span class="math inline">\(Y=y\)</span>, deriving the specific value. In practice, we will typically compute <span class="math inline">\(E[X|Y]\)</span> rather than <span class="math inline">\(E[X|Y=y]\)</span>, since once we have <span class="math inline">\(E[X|Y]\)</span> we can easily find <span class="math inline">\(E[X|Y=y]\)</span> for <em>every</em> value of <span class="math inline">\(y\)</span>.</p>
<p>TODO: Show example.</p>
<p>Since <span class="math inline">\(E[X|Y]\)</span> is a function of an unknown random quantity, <span class="math inline">\(Y\)</span>, <span class="math inline">\(E[X|Y]\)</span> is also a random variable. It is a transformation of <span class="math inline">\(Y\)</span>, and as such, it will have some distribution, some expectation, and some varaince itself. This is often a confusing concept when it is first introduced, so to recap: <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are both random variables; $E[X] and <span class="math inline">\(E[Y]\)</span> are both constant, numerical values describing the distribution of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>; <span class="math inline">\(E[X|Y=y]\)</span> and <span class="math inline">\(E[Y|X=x]\)</span> are each numeric constants which summarize the distribution of <span class="math inline">\(X|Y=y\)</span> and <span class="math inline">\(Y|X=x\)</span> respectively; <span class="math inline">\(E[X|Y]\)</span> and <span class="math inline">\(E[Y|X]\)</span> are functions of <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>, respectively, and can as such be seen as transformations of (and random quantities depending on) <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> respectively.</p>
<p>We do not often think of the distribution of <span class="math inline">\(E[X|Y]\)</span> directly, however, there is a very useful result about both its expected value and its variance, which will commonly be exploited. Specifically, if we take the expected value of <span class="math inline">\(E[X|Y]\)</span> we will find that <span class="math inline">\(E[E[X|Y]] = E[X]\)</span>. Note that since <span class="math inline">\(E[X|Y] = g(Y)\)</span> for some transformation, <span class="math inline">\(g\)</span>, the outer expectation is taken with respect to the distribution of <span class="math inline">\(Y\)</span>. Sometimes when this may get confusing we will use notation to emphasize this fact, specifically, <span class="math inline">\(E_Y[E_{X|Y}[X|Y]] = E_X[X]\)</span>. This notation is not necessary, but it can clarify when there is much going on, and is a useful technique to fallback on. <span class="math display">\[\begin{align*}
E_Y[E[X|Y]] &amp;= \sum_{y\in\mathcal{Y}} E[X|Y]p_Y(y) \\
&amp;= \sum_{y\in\mathcal{Y}}\left(\sum_{x\in\mathcal{X}}xp_{X|Y}(x|Y)\right)p_Y(y) \\
&amp;= \sum_{y\in\mathcal{Y}}\sum_{x\in\mathcal{X}}x\frac{p_{X,Y}(x,y)}{p_Y(y)}p_Y(y)\\
&amp;= \sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}xp_{X,Y}(x,y)\\
&amp;= \sum_{x\in\mathcal{X}} xp_X(x)\\
&amp;= E[X].\end{align*}\]</span></p>
<p>TODO: Include example.</p>
<p>This property, that <span class="math inline">\(E[E[X|Y]] = E[X]\)</span> is important enough that it receives its own name: <strong>the law of total expectation</strong>. In the same way that it is sometimes easier to first condition on <span class="math inline">\(Y\)</span> in order to compute the marginal distribution of <span class="math inline">\(X\)</span> via applications of the law of total probability, so too can it be easier to first work out conditional expectations, and then take the expected value of the resulting expression. This adds on to the so-called ``conditioning arguments’’ that were discussed previously, allowing a technique to work out the marginal mean indirectly.</p>
<p>TODO: Show example use case of LOTE.</p>
<p>While the conditional expectation is used quite prominantly, the conditional variance is less central to the study of random variables. As discussed, briefly, the conditional variance is given by the same variance relationship, replacing the marginal probability distribution with the conditional one (just as with expectations). Just as with expectations, <span class="math inline">\(\text{var}(X|Y=y)\)</span> is a numeric quantity given by <span class="math inline">\(E[(X-E[X|Y=y])^2|Y=y]\)</span> and <span class="math inline">\(\text{var}(X|Y)\)</span> is a random variable given by <span class="math inline">\(E[(X-E[X|Y])^2|Y]\)</span>. This means that when working with the general, <span class="math inline">\(\text{var}(X|Y)\)</span>, we can also consider taking expectations of the resulting transformation.</p>
<p>TODO: Include examples.</p>
<p>A final result relating to conditional expectations and varainces connects the two concepts. This is known as <strong>the law of total variance</strong>. For any random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, we can write <span class="math display">\[\text{var}(X) = E[\text{var}(X|Y)] + \text{var}(E[X|Y]).\]</span> This result can be viewed as decomposing thevariance of a random quantity into two separate components, and comes up again in later statistics courses. At this point we can view this as a method for connecting the marginal distribution through the conditional variance nad expectation.</p>
<p>TODO: Examples of this.</p>
<p>The final set of techniques to consider for now relate to making use of the joint distribution between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Specifically, if we have any function of two random variables, say <span class="math inline">\(g(X,Y)\)</span> and we wish to find <span class="math inline">\(E[g(X,Y)]\)</span>. This follows all of the expected derivations that we have used so far, this time replacing the marginal with the joint distribution. That is, <span class="math display">\[E[g(X,Y)] = \sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}g(x,y)p_{X,Y}(x,y).\]</span> For instance, if we want to consider the product of two random variables, we could use this technique to determine <span class="math inline">\(E[XY]\)</span>. The variance extends in the same manner as well.</p>
<p>TODO: Include example.</p>
<p>This defining relationship allows us to work out the expected value of a linear combination of two random variables. That is <span class="math display">\[\begin{align*}
E[X+Y] &amp;= \sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}(x+y)p_{X,Y}(x,y) \\
&amp;= \sum_{x\in\mathcal{X}}x\sum_{y\in\mathcal{Y}}p_{X,Y}(x,y) + \sum_{y\in\mathcal{Y}}y\sum_{x\in\mathcal{X}}p_{X,Y}(x,y) \\
&amp;= \sum_{x\in\mathcal{X}}xp_X(x) + \sum_{y\in\mathcal{Y}}yp_Y(y) \\
&amp;= E[X] + E[Y].\end{align*}\]</span></p>
<p>The same property does not apply with varainces, at least not in general. To see this, consider that <span class="math display">\[\begin{align*}
E[(X+Y-E[X]-E[Y])^2] &amp;= E[((X-E[X])+(Y-E[Y]))^2] \\
&amp;= E[(X-E[X])^2] + E[(Y-E[Y])^2] + 2E[(X-E[X])(Y-E[Y])] \\
&amp;= \text{var}(X) + \text{var}(Y) + 2E[(X-E[X])(Y-E[Y])].\end{align*}\]</span> The term that impedes the linear relationship, <span class="math inline">\(E[(X-E[X])(Y-E[Y])]\)</span> can be computed as any joint function can be. This quantity, however, is particularly important when considering the relationship between two random variables. This is called the <strong>covariance</strong> and it is a measure of the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Typically we write <span class="math inline">\(E[(X-E[X])(Y-E[Y])] = \text{cov}(X,Y)\)</span> so that <span class="math display">\[\text{var}(X+Y) = \text{var}(X) + \text{var}(Y) + 2\text{cov}(X,Y).\]</span></p>
<p>TODO: Include example.</p>
<p>The covariance behaves similarly to the varaince. We can see directly from the definition that <span class="math inline">\(\text{cov}(X,X) = \text{var}(X)\)</span>. Moreover, using similar arguments to those used for the varaince, we can show that <span class="math display">\[\text{cov}(aX+b,cY+d) = ac\text{cov}(X,Y).\]</span> Covariances remain linear, so that <span class="math display">\[\text{cov}(X+Y,X+Y+Z)=\text{cov}(X,X)+\text{cov}(X,Y)+\text{cov}(X,Z)+\text{cov}(Y,X)+\text{cov}(Y,Y)+\text{cov}(Y,Z).\]</span> These make covariances somewhat nicer to deal with than variances, and on occasion it may be easier to think of variances as covariances with themselves.</p>
<p>TODO: Example? Maybe.</p>
<p>It is worth considering, briefly, the ways in which conditional and joint expectations interact. Namely, if we know that <span class="math inline">\(Y=y\)</span>, then the transformation <span class="math inline">\(g(X,y)\)</span> only has one random component, which is the <span class="math inline">\(X\)</span>. As a result, taking <span class="math inline">\(E[g(X,Y)|Y=y] = E[g(X,y)|Y=y]\)</span>. If instead we use the conditional distribution without a specific value, we still have that <span class="math inline">\(Y\)</span> is fixed within the expression, it is just fixed to an unknown quantity. That is <span class="math inline">\(E[g(X,Y)|Y]\)</span> will be a function of <span class="math inline">\(Y\)</span>. We saw before that <span class="math inline">\(E[E[X|Y]] = E[X]\)</span>, and the same is true in the joint case. Thus, one technique for computing the joint expectation, <span class="math inline">\(g(X,Y)\)</span> is to first compute the conditional expectation, and then compute the marginal expectation of the resulting quantity.</p>
<p>TODO: example.</p>
</section>
<section id="independence-in-all-of-this" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="independence-in-all-of-this"><span class="header-section-number">5.4</span> Independence in all of this</h2>
<p>Whenever we can assume independence of random quantities, this allows us to greatly simplify teh expressions we are dealing with. Recall that the key defining relationship with independence is that <span class="math inline">\(p_{X,Y}(x,y) = p_X(x)p_Y(y)\)</span>. Suppose then that we can write <span class="math inline">\(g(X,Y) = g_X(X)g_Y(Y)\)</span>. For instance, for the covariance we have <span class="math inline">\(g(X,Y)=(x-E[X])(Y-E[Y])\)</span> and so <span class="math inline">\(g_X(X) = X-E[X]\)</span> and <span class="math inline">\(g_Y(Y) = Y-E[Y]\)</span>. If we want to compute <span class="math inline">\(E[g(X,Y)]\)</span> then we get <span class="math display">\[\begin{align*}
E[g(X,Y)] &amp;= E[g_X(X)g_Y(Y)] \\
&amp;= \sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}g_X(x)g_Y(y)p_{X,Y}(x,y) \\
&amp;= \sum_{x\in\mathcal{X}}\sum_{y\in\mathcal{Y}}g_X(x)g_Y(y)p_X(x)p_Y(y) \\
&amp;=\sum_{x\in\mathcal{X}}g_X(x)p_X(x)\sum_{y\in\mathcal{Y}}g_Y(y)p_Y(y)\\
&amp;= E[g_X(X)]E[g_Y(Y)].\end{align*}\]</span> Thus, whenever random variables are independent, we have the ability to separate them over their expectations.</p>
<p>TODO: example.</p>
<p>Consider what this means, in particular, for the covariance between independent random variables. If <span class="math inline">\(X\perp Y\)</span> then <span class="math display">\[\begin{align*}
\text{cov}(X,Y) &amp;= E[(X-E[X])(Y-E[Y])] \\
&amp;= E[(X-E[X])]E[(Y-E[Y])] \\
&amp;= (E[X]-E[X])(E[Y]-E[Y]) \\
&amp;= 0.\end{align*}\]</span> That is to say, if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are indepdent, then <span class="math inline">\(\text{cov}(X,Y)=0\)</span>. As a result of this, for independent random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> we also must have that <span class="math inline">\(\text{var}(X+Y)=\text{var}(X)+\text{var}(Y)\)</span>. It is critical to note that this relationship does not go both ways: you are able to have <span class="math inline">\(\text{cov}(X,Y) = 0\)</span> even if <span class="math inline">\(X\not\perp Y\)</span>.</p>
<p>TODO: Include example of independence.</p>
<p>While we have primarily focused on joint and conditional probabilities with two random variables, the same procedures and ideas apply with three or more as well. The relevant joint distribution, or conditional distribution would simply need to be substituted in definitions. Often the complexity here becomes a matter of keeping track of which quantities are random, and which are not. For instance, if we have <span class="math inline">\(X,Y,Z\)</span> as random variables, then <span class="math inline">\(E[X|Y,Z]\)</span> is a random function of <span class="math inline">\(Y\)</span> and <span class="math inline">\(Z\)</span>. We will still have that <span class="math inline">\(E[E[X|Y,Z]] = E[X]\)</span>, however, the outer expectation is now the joint expectation with respect to <span class="math inline">\(Y\)</span> and <span class="math inline">\(Z\)</span>. As a result, we can also write <span class="math inline">\(E[E[X|Y,Z]|Y]\)</span>. The first expectation will be with respect to <span class="math inline">\(X|Y,Z\)</span>, while the outer expectation is with respect to <span class="math inline">\(Z|Y\)</span>. This becomes a useful demonstration for when making the distribution of the expectation explicit helps to clarify what is being computed. As a general rule of thumb, the innermost expectations will always have more conditioning variables than the outer ones: each time we step out, we peel back one of hte conditional variables until the outermost is either a marginal (or joint). This will help to keep things clear.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          trigger: 'click',
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          positionFixed: true,
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../notes/chapter4.html" class="pagination-link  aria-label=" &lt;span="" with="" more="" than="" one="" event&lt;="" span&gt;"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Probailities with More than One Event</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../notes/chapter6.html" class="pagination-link" aria-label="<span class='chapter-number'>6</span>&nbsp; <span class='chapter-title'>The Named Discrete Distributtions</span>">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The Named Discrete Distributtions</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>