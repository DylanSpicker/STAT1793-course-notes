<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.533">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>STAT 1793: Course Notes - 4&nbsp; Probailities with More than One Event</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../notes/chapter5.html" rel="next">
<link href="../notes/chapter3.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "classic",
  "enableExperimentalNewNoteButton": true,
  "showHighlights": "whenSidebarOpen"
}
</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notes/chapter1.html">Part 1: Probability</a></li><li class="breadcrumb-item"><a href="../notes/chapter4.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Probailities with More than One Event</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">STAT 1793: Course Notes</a> 
        <div class="sidebar-tools-main">
    <a href="../STAT-1793--Course-Notes.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Part 1: Probability</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Mathematical Foundations of Statistical Experiments</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Core Concepts of Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter4.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Probailities with More than One Event</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Random Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The Named Discrete Distributtions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notes/chapter7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Continuous Random Variables</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Part 2: Statistics</span></span>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#conditional-probability-and-related-theorems" id="toc-conditional-probability-and-related-theorems" class="nav-link active" data-scroll-target="#conditional-probability-and-related-theorems"><span class="header-section-number">4.1</span> Conditional Probability (and related theorems)</a></li>
  <li><a href="#independence" id="toc-independence" class="nav-link" data-scroll-target="#independence"><span class="header-section-number">4.2</span> Independence</a></li>
  <li><a href="#contingency-tables" id="toc-contingency-tables" class="nav-link" data-scroll-target="#contingency-tables"><span class="header-section-number">4.3</span> Contingency Tables</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notes/chapter1.html">Part 1: Probability</a></li><li class="breadcrumb-item"><a href="../notes/chapter4.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Probailities with More than One Event</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Probailities with More than One Event</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="conditional-probability-and-related-theorems" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="conditional-probability-and-related-theorems"><span class="header-section-number">4.1</span> Conditional Probability (and related theorems)</h2>
<p>Regardless of whether we are using the equally likely outcome model, or not, there are several properties of probability which can be derived that are either of direct interest themselves, or else are useful for manipulating probability expressions. These rules apply to any probability model, and greatly increase the flexibility of working with these models.</p>
<p>Up until this point we have primarily focused on assigning probabilities to particular events. If we have some event of interest, <span class="math inline">\(A\)</span>, then <span class="math inline">\(P(A)\)</span> is the probability that <span class="math inline">\(A\)</span> occurs in any manner. If we are using our equally likely probability model, then <span class="math inline">\(P(A) = \frac{N_A}{N}\)</span>. This is the probability of the event <span class="math inline">\(A\)</span> where nothing else is known at all. If we smooth over anything which could alter the likelihood, if we have no additional information, if we want the best guess for the likelihood of occurence in a vaccuum, this is the probability of interest. We refer to such quantities as <strong>marginal probabilities</strong>.</p>
<p>While marginal probabilities are often of interest, and frequently are the best tool for summarizing the overall state of the world (or our knowledge regarding the state of the world), in pracctice we know that sometimes information that we have will change our understanding of the probability of an event. Suppose the event <span class="math inline">\(A\)</span> corresponds to the event that it snows tomorrow, in some particular city. It is possible to think about how often it snows on average, and report a value related to that as <span class="math inline">\(P(A)\)</span>. Now, what if we know that it is currently the middle of summer? In this case, while <span class="math inline">\(P(A)\)</span> does not shrink to <span class="math inline">\(0\)</span>, it becomes far less likely than if we did not have that information. Similarly, if we know that it is winter, the likelihood that it snows tomorrow increases.</p>
<p>In order to formall capture this we can introduce the idea of <strong>conditional probability</strong>. Unlike in the cas of marginal probabilities, conditional probabilities allow us to <em>condition</em> on extra pieces of information. Instead of asking “what is the porbability of this event”, they instead ask, “given that we know this piece of information, what is the probability of this event?” The subtle distinction becomes quite powerful, both in terms of manipulating and working with probabilities, but also in terms of expressing the correct events of interest for ourselves.</p>
<p>To make use of conditional probabilities, we will think of the process of <strong>conditioning</strong> on (one or more) events. That is, we will talk of the probability of <span class="math inline">\(A\)</span> conditional on <span class="math inline">\(B\)</span>, where <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are two events of interest. We write this quantity as <span class="math inline">\(P(A|B)\)</span>, and typically will read this as “the probability of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span>.” Intuitively, this it the probability of <span class="math inline">\(A\)</span> happening, supposing that we know that <span class="math inline">\(B\)</span> has already happened.</p>
<p>TODO: Include some examples.</p>
<p>Recall that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, as events, are merely subsets of the sample space, <span class="math inline">\(\mathcal{S}\)</span>. Each item in either <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span> is one of the possible outcomes from the experiment or process that we are observing. Suppose that we know that <span class="math inline">\(B\)</span> has occurred. What this means is that, one of the outcomes in the set <span class="math inline">\(B\)</span> was the observed outcome from the experiment. Now, if we want to know <span class="math inline">\(P(A|B)\)</span>, we want to know the probability, working from the assumption that <span class="math inline">\(B\)</span> has happened, that <span class="math inline">\(A\)</span> also happens. That is, knowing that <span class="math inline">\(B\)</span> has happened, what is the probability that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> happen.</p>
<p>Thinking back to our discussion of events, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> is denoted by <span class="math inline">\(A \cap B\)</span>, and it corresponds to the set of events inside the set <span class="math inline">\(B\)</span>, which also belong to the set <span class="math inline">\(A\)</span>. Now, instead of considering the event <span class="math inline">\(P(A\cap B)\)</span> directly, we need to acknowledge that for <span class="math inline">\(A|B\)</span>, only the events in <span class="math inline">\(B\)</span> were possible. That is, instead of being divided by the whole space, we can only divide by the space of <span class="math inline">\(B\)</span>. In some sense, we can view conditioning on <span class="math inline">\(B\)</span> as treating <span class="math inline">\(B\)</span> as though it is the full sample space, and finding probabilities within that. In general, <span class="math inline">\(B\)</span> will be smaller than <span class="math inline">\(\mathcal{S}\)</span>, and so <span class="math inline">\(P(B) &lt; 1\)</span>. Instead of the conditional probability being “out of” <span class="math inline">\(1\)</span>, it will instead be “out of” <span class="math inline">\(P(B)\)</span>, which gives <span class="math inline">\(P(A|B) = \frac{P(A\cap B)}{P(B)}\)</span>.</p>
<p>To make this more clear, let’s consider a simple example. Suppose that we take <span class="math inline">\(A\)</span> to be the event that a <span class="math inline">\(2\)</span> is rolled on a fair, six-sided die, and <span class="math inline">\(B\)</span> to be the event that an even number was rolled. This is an equal probability model, and so each outcome gets <span class="math inline">\(\frac{1}{6}\)</span> probability. The original sample space is <span class="math inline">\(\mathcal{S} = \{1,2,3,4,5,6\}\)</span>, the event <span class="math inline">\(A\)</span> is <span class="math inline">\(\{2\}\)</span>, and the event <span class="math inline">\(B\)</span> is <span class="math inline">\(\{2,4,6\}\)</span>. In order for both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> to occur, we note that we need <span class="math inline">\(A \cap B = \{2\}\)</span>. If we know that <span class="math inline">\(B\)</span> has occured, then we know that either a <span class="math inline">\(2\)</span>, <span class="math inline">\(4\)</span>, or <span class="math inline">\(6\)</span> has been rolled, with equal probability for each. Thus, intuitively, we can view <span class="math inline">\(B\)</span> as the new sample space, and say that rolling a <span class="math inline">\(2\)</span> has a <span class="math inline">\(\frac{1}{3}\)</span> probability, given that there are <span class="math inline">\(3\)</span> outcomes and <span class="math inline">\(1\)</span> of them is the event of interest. Another way to consider this is to note that <span class="math inline">\(P(B) = \frac{1}{2}\)</span>, and so we need to scale each event by <span class="math inline">\(\frac{1}{1/2}\)</span> in order to make sure that the total probability of our reduced sample space equals <span class="math inline">\(1\)</span>. Then <span class="math inline">\(P(A\cap B) = \frac{1}{6}\)</span>, so <span class="math display">\[P(A|B) = \frac{1/6}{1/2} = \frac{1}{3}.\]</span></p>
<p>TODO: try rewriting this a bit.</p>
<p>Suppose that, instead of a fair die, it was weighted so that <span class="math inline">\(6\)</span> comes up more frequently than the other options, coming up with probability <span class="math inline">\(0.5\)</span>, and the other fives each coming up with probability <span class="math inline">\(0.10\)</span>. If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are the same events as above, then <span class="math inline">\(P(B) = 0.7\)</span> now. If we know that <span class="math inline">\(B\)</span> has occurred, then the new sample space is <span class="math inline">\(\{2,4,6\}\)</span> where <span class="math inline">\(P(2) = \frac{0.1}{0.7} = \frac{1}{7}\)</span>, <span class="math inline">\(P(4) = \frac{0.1}{0.7}\)</span>, and <span class="math inline">\(P(6) = \frac{0.5}{0.7} = \frac{5}{7}\)</span>. Note that these three probabilities sum to <span class="math inline">\(1\)</span> still, which constitutes a valid probability model, and so <span class="math inline">\(P(A|B) = \frac{1}{7}\)</span>.</p>
<p>TODO: Add example about this.</p>
<p>Ultimately, the conditional probability of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span> is gtgiven the definition of <span class="math display">\[P(A|B) = \frac{PA\cap B}{P(B)}.\]</span> This is defined only for when <span class="math inline">\(P(B) &gt; 0\)</span>. The numerator in the expression, <span class="math inline">\(P(A \cap B)\)</span> is called the <strong>joint probability</strong> of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, and may also be written as <span class="math inline">\(P(A,B)\)</span>. Sometimes, we wish to condition on more than one event. To do so, the same process extends naturally. For instance, suppose we want to know the probability of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>. This would be written <span class="math display">\[P(A|B,C) = \frac{P(A\cap B\cap C)}{P(B \cap C)} = \frac{P(A,B,C)}{P(B,C)}.\]</span> Moving beyond two events occurs in the expected way.</p>
<p>Conditional probability is a mechanism for capturing our knowledge of the world, and using that to update our sense of the uncertainties at play. For instance, suppose that we are interested in drawing a random card from a deck of <span class="math inline">\(52\)</span>, and we want to know the probability that it is a heart. Without any additional knowledge, the probability of this event is <span class="math inline">\(\frac{1}{4}\)</span>. Now, suppose that you know that it is a red card. In this case, we now know that itis either a heart or a diamond, and there are equal numbes of each, meaning that the new probability is <span class="math inline">\(0.5\)</span>. We can work this out directly <span class="math display">\[P(\text{Heart}|\text{Red}) = \frac{P(\text{Heart},\text{Red})}{P(\text{Red})} = \frac{P(\text{Heart})}{1/2} = \frac{1/4}{1/2} = 0.5.\]</span> Suppose instaead that wwe had been told that the card was an ace. Here we now know that there are four possible outcomes that correspond to an ace, and only one of these is a heart, meaning the probability is <span class="math inline">\(\frac{1}{4}\)</span>. In this case, <span class="math inline">\(P(A|B) = P(A)\)</span>, and our beliefs did not update.</p>
<p>What if instead we had considered the second event to be “the card was a spade.” In this case if we want to know <span class="math inline">\(P(A|B)\)</span> then, given a spade being drawn, we know that the probability of drawing a heart is <span class="math inline">\(0\)</span>.</p>
<p>TODO: Add further examples of conditional probabilities.</p>
<p>While sometimes we will want to work out the conditional probability, knowing the joint and marginal probabilities, there are other times where it is easier to determine the conditional probability directly, but where we wish to understand the marginal probability. That is, we may be able to know <span class="math inline">\(P(A|B)\)</span>, but we want ot make statements regarding <span class="math inline">\(P(A)\)</span> or <span class="math inline">\(P(A,B)\)</span>.</p>
<p>In this case, we can simply rearrange the defining relationship of conditional probability, to solve for the quantities of interest. Because of the importance of this procedure, we actually give the most straightforward rearrangment a special name. Note that, by multiplying both sides of the definition of <span class="math inline">\(P(A|B)\)</span> by <span class="math inline">\(P(B)\)</span>, wwe get that <span class="math display">\[P(A\cap B) = P(A|B)P(B).\]</span> This is known as the <strong>multiplication rule</strong>. In particular, it states that we can solve for the joint probability of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> by multiplying the conditional probability of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span>, by the marginal probability of <span class="math inline">\(B\)</span>. Note that this is symmetric in <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> so that <span class="math display">\[P(A\cap B) = P(B|A)P(A).\]</span> This is useful as sometimes it is easier to determine <span class="math inline">\(B\)</span> given <span class="math inline">\(A\)</span>.</p>
<p>TODO: Example regarding the multiplication rule.</p>
<p>While the multiplication rule gives us the capacity to solve for joint probabilities, often we wish to make statements regarding marginal probabilities. Fortunately, we can extend this process outlined in the multiplication rule to solve directly for marginal probabilities as well. To do so, we first introduce the concept of a <strong>partition</strong>.</p>
<p>A <strong>partition</strong> is simply a collection of sets which divide up the sample space such that all of the sets are disjoint from one another, and there is no overlap between any of the sets. For instance, if the sample space were all the positive integers, we could partition this space into all the even numbers as one set and all the odd numbers as a second. We could also partition this into the set of numbers which are less than <span class="math inline">\(10\)</span>, the set of numnbers that are greater than <span class="math inline">\(10\)</span>, and then <span class="math inline">\(10\)</span>. In both examples we have sets that form the full sample space with no overlap. In notation, if our partition is formed of <span class="math inline">\(B_1, B_2, B_3, \dots\)</span>, then we require <span class="math inline">\(\bigcup_i B_i = \mathcal{S}\)</span> and that <span class="math inline">\(B_i \cap B_\ell = \emptyset\)</span>. Note that we could not partition the set into multiples of <span class="math inline">\(2\)</span> and multiples of <span class="math inline">\(3\)</span>, since (i) not all values are contained between these two sets, and (ii) there is overlap between these two sets.</p>
<p>TODO: Include further partition examples</p>
<p>Given a partition, <span class="math inline">\(B_1, B_2, \dots\)</span>, suppose that we can work out both <span class="math inline">\(P(B_i)\)</span> for all <span class="math inline">\(i\)</span>, and <span class="math inline">\(P(A|B_i)\)</span> for all <span class="math inline">\(i\)</span>. In this case we can work out the marginal probability of <span class="math inline">\(A\)</span> using <strong>the law of total probability</strong>. To do so we take <span class="math display">\[P(A) = \sum_i P(A|B_i)P(B_i).\]</span> Intuitively, since the whole sample space is divided into the different <span class="math inline">\(B_i\)</span>s, this rule breaks down the calculation of <span class="math inline">\(A\)</span> happening into manageable chunks. Each term in the summation is “the probability that <span class="math inline">\(A\)</span> happens, given <span class="math inline">\(B_i\)</span> happening” weighted by how likely it is that <span class="math inline">\(B_i\)</span> happens. Then by summing over all possible <span class="math inline">\(B_i\)</span>, we know that we must be capturing all possible ways that <span class="math inline">\(A\)</span> can occur since all parts of the sample space are contained in exactly one of the sets of our partition.</p>
<p>The law of total probability is an indispensible tool for computing probabilities in practice. Suppose that an online retailer uses two different services to send out their packages, the first one delivers later with probability <span class="math inline">\(0.05\)</span> and the second delivers late with probability <span class="math inline">\(0.1\)</span>. If the chances that a customer selects the first supplier are <span class="math inline">\(0.75\)</span>, then with this information we can work out the probability that any randomly selected package will be late. First note that in this case our sample space is comprised of <span class="math inline">\(\mathcal{S} = \{(L,A),(L,B),(O,A),(O,B)\}\)</span> where <span class="math inline">\(L\)</span> stands for late, <span class="math inline">\(O\)</span> for on time, <span class="math inline">\(A\)</span> for the first compnay, and <span class="math inline">\(B\)</span> for the second. We want to know <span class="math inline">\(P(L)\)</span>, where <span class="math inline">\(L = \{(L,A),(L,B)\}\)</span>. Note that we can partition the space into those sent by <span class="math inline">\(A\)</span> and those sent by <span class="math inline">\(B\)</span>, and we know that <span class="math inline">\(P(A) = 0.75\)</span> and <span class="math inline">\(P(B) = 0.25\)</span>. Moreover, we know that <span class="math inline">\(P(L|A) = 0.05\)</span> and <span class="math inline">\(P(L|B) = 0.10\)</span> and so combining this all together we get <span class="math display">\[P(L) = P(L|A)P(A) + P(L|B)P(B) = (0.05)(0.75) + (0.10)(0.25) = 0.0625.\]</span></p>
<p>TODO: Write another example on the utility of L.o.T.P.</p>
<p>We have seen the direct computation of marginal probabilities (while using an equally likely outcome model), the computation of conditional probabilities, the use of the multiplication rule for joint probabilities, and the use of the law of total probability to indirectly calculate marginal probabilities through conditioning arguments. Throughout these discussions we have been primarily concerned with keeping events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> arbitrary. Everything that we have indicated for <span class="math inline">\(P(A)\)</span> holds for <span class="math inline">\(P(B)\)</span>, as does <span class="math inline">\(P(A|B)\)</span> and <span class="math inline">\(P(B|A)\)</span>. In reality, it will often be the case that conditioning on one of the events will be natural, while conditioning on the other will be more tricky. In these events, it can be useful to be able to transform statements regarding <span class="math inline">\(P(A|B)\)</span> into statements regarding <span class="math inline">\(P(B|A)\)</span>, and vice versa.</p>
<p>Note that the symmetry of definitions gives the fact that <span class="math display">\[P(A|B)P(B) = P(A,B) = P(B|A)P(A).\]</span> This is an application of the multiplication rule in two different orientations. If we divide both sides of the equality by <span class="math inline">\(P(B)\)</span>, assuming that it is not <span class="math inline">\(0\)</span>, then we get <span class="math display">\[P(A|B) = \frac{P(B|A)P(A)}{P(B)}.\]</span> Now, if we form a partition, say <span class="math inline">\(A,A_2,A_3,\cdots\)</span>, then we can rewrite <span class="math inline">\(P(B)\)</span> using the law of total probability as <span class="math display">\[P(B) =  P(B|A)P(A) + P(B|A_2)P(A_2) + \cdots,\]</span> which can replace <span class="math inline">\(P(B)\)</span> in the expression. Taken together, we refer to this relationship as <strong>Bayes’ Theorem</strong>, and it is typically expressed as <span class="math display">\[P(A|B) = \frac{P(B|A)P(A)}{P(B|A)P(A) + \sum_i P(B|A_i)P(A_i)}.\]</span></p>
<p>Bayes’ Theorem allows us to convert statements regarding <span class="math inline">\(P(B|A)\)</span> into statements regarding <span class="math inline">\(P(A|B)\)</span>. Note that, as we derived above, Bayes’ Theorem is really just an application of the multiplication rule and an application of the law of total probability. Sometimes we may have <span class="math inline">\(P(B)\)</span> directly, rendering the law of total probability in the denominator unnecessary. Often, the natural partition to select when we do need the law of total probability is to take <span class="math inline">\(A,A^C\)</span>. Note that any set with its complement forms a partition, since by definition they occupy the entire space and are non-overlapping. When this is done we get the slightly more compact relationship of <span class="math display">\[P(A|B) = \frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A^C)P(A^C)}.\]</span></p>
<p>Unlike our previous relationships, Bayes’ Theorem allows us to translate one set of conditional knowledge into another. The most common example application is in medical testing. Suppose that we know the performance characteristics of a particular medical test: it is <span class="math inline">\(99\%\)</span> accurate for positive cases, and <span class="math inline">\(95\%\)</span> accurate for negative cases. That is, wit h probability <span class="math inline">\(0.99\)</span> it correctly returns positive when an individual is infected, and with probability <span class="math inline">\(0.95\)</span> it returns negative when an individual is not infected. These are both statements of conditional probability. If we take <span class="math inline">\(A\)</span> to be the event that the test returns positive, and <span class="math inline">\(B\)</span> to be the event that the patient is infected, then we are saying that <span class="math inline">\(P(A|B) = 0.99\)</span> and <span class="math inline">\(P(A^C|B^C) = 0.95\)</span> which means that <span class="math inline">\(P(A|B^C) = 0.05\)</span>. Suppose that we know that, across the entire population, one in a thousand individuals is likely to be infected. This means that <span class="math inline">\(P(B) = 0.001\)</span>. Now suppose that a random individual goes into a doctor’s appointment, and tests positive for the disease. How likely are they to actually be infected?</p>
<p>Note that in this case we want to know the probability of them being infected given that they have tested positive. In notation, this is <span class="math inline">\(P(B|A)\)</span>. We do not know this quantity directly, but given a simple application of Bayes’ Theorem, we can work it out. Here using the natural partition of <span class="math inline">\(B,B^C\)</span>, we get <span class="math display">\[P(B|A) = \frac{P(A|B)P(A)}{P(A|B)P(B)+P(A|B^C)P(B^C)} = \frac{(0.99)(0.001)}{(0.99)(0.001)+(0.05)(0.999)} \approx 0.019.\]</span> That is, despite the fact that this test is exceptionally effective at detecting this disease, a positive test still means that an individual has a probability of only <span class="math inline">\(0.019\)</span> of actually having the illness. This counter intuitive fact was an intensely frustrating reality for statisticians everywhere during the height of the COVID-19 pandemic, when politicians and the population at large turned away from testing owing to its perceived ineffectiveness.</p>
<p>TODO: Add another exmaple regarding Bayes’ Theorem</p>
<p>Bayes’ Theorem highlights a key lesson when considering conditional probabilities, and it’s a common mistake to make which should be avoided at all costs. Namely, we cannot interchange <span class="math inline">\(P(A|B)\)</span> with <span class="math inline">\(P(B|A)\)</span>. These probabilities are not necessarily highly correlated with one another, and it is important to distinguish clearly which is the probability of interest. Mixing up <span class="math inline">\(P(B|A)\)</span> and <span class="math inline">\(P(A|B)\)</span> is often called “confusion of the inverse,” and it can lead to very faulty conclusions when ignored. In the medical testing example above, it is important to not confuse “the probability that the test returns positive, assuming you have theillness” with “the probability that you have the illness, given that the test returns positive.” The stakes of these types of confusion can be quite high, and it is tremendously important to ensure that you are conditioning on the correct events. Fortunately, Bayes’ Theorem allows us to translate ebtween events for conditioning, giving a mecchanism from translating between the two.</p>
<p>TODO: Include Another Example (perhaps Smoking vs.&nbsp;lung cancer)</p>
<p>TODO: Fix Bayes’ to Bayes’</p>
<p>TODO: Add in subsections</p>
</section>
<section id="independence" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="independence"><span class="header-section-number">4.2</span> Independence</h2>
<p>We have seen that, in most cases, when we have conditioned on an event it has changed the probability of that event. For instance, if we want to know the probability it is raining, if we condition on knowing that it is a day full of gray skies, then the probability likely increases. By considering how tehse probabilities change when we condition, we are in effect indicating a dependence of the events on one another. In terms of probability, this dependence is captured by an influence on the degree of uncertainty present, depending on what we know.</p>
<p>It is of course, totally possible that two events do not influence one another. The weeather outside today is likely not influenced by your favourite sports team’s performance last night, for instance. In this case, we would be suggest that <span class="math inline">\(P(A|B) = P(A)\)</span>. We saw an example where this was concerned previously when we wanted to know the probability of a randomly selected card being a heart (<span class="math inline">\(A\)</span>), given that it was an ace (<span class="math inline">\(B\)</span>). We found tat this was <span class="math inline">\(\frac{1}{4}\)</span>, exactly the same as the probability if we did not know that it was an ace. Thus here we have <span class="math inline">\(P(A|B)=P(A)\)</span>. Note that in this case, we could have also said that <span class="math inline">\(P(B|A)=P(B)=\frac{1}{13}\)</span>.</p>
<p>The symmetry of these events makes it somewhat more convenient to express this relationship differently. If we multiply both sides of the <span class="math inline">\(P(A|B)=P(A)\)</span>, by <span class="math inline">\(P(B)\)</span>, then applying the multiplication rule gives <span class="math display">\[P(A,B) = P(A)P(B).\]</span> Any two events that satisfy this relationship are said to be <strong>independent</strong>. If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent we write <span class="math inline">\(A\perp B\)</span>.</p>
<p>Note that independence is always a symmetric property: if <span class="math inline">\(A\)</span> is independent of <span class="math inline">\(B\)</span>, then <span class="math inline">\(B\)</span> is independent of <span class="math inline">\(A\)</span>. To check whether two evetns are independent, we simply need to check whether their joint probability (that is, the proobability of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>) is equal to the product of their marginal probabilities. If <span class="math inline">\(P(A)\neq 0\)</span>, then we can divide both sides by <span class="math inline">\(P(A)\)</span> to gives <span class="math inline">\(P(B|A) = P(B)\)</span>. Similarly, if <span class="math inline">\(P(B)\neq 0\)</span>, then we can divide both sides by <span class="math inline">\(P(B)\)</span> to give <span class="math inline">\(P(A|B)=P(A)\)</span>.</p>
<p>This expression in terms of conditional probabilities is the more intuitive expression of independence. It directly captures the idea that “knowing <span class="math inline">\(B\)</span> does not change our beleif about <span class="math inline">\(A\)</span>”, which is how independence is best thought of. However, we must be careful. This conditional argument is only valid when the event that is being conditioned on is not probability <span class="math inline">\(0\)</span>, where the defining relationship, <span class="math inline">\(P(A,B) = P(A)P(B)\)</span>, will hold for any events.</p>
<p>TODO: Example assessing the independence of several events.</p>
<p>When two events are not independent, we say that they are dependent, and may sometimes write <span class="math inline">\(A\not\perp B\)</span>. Note that we saw that, in general, <span class="math inline">\(P(A\cap B) =  P(A)+P(B)-P(A\cup B)\)</span>. It is only when assuming independence that this simplifies further.</p>
<p>Importantly, if <span class="math inline">\(A\perp B\)</span>, then <span class="math inline">\(A\cap B\neq \emptyset\)</span> unless either <span class="math inline">\(A=\emptyset\)</span> or <span class="math inline">\(B=\emptyset\)</span> or both. To see this recall that <span class="math inline">\(P(\emptyset) = 0\)</span>, and so if <span class="math inline">\(A\cap B = \emptyset\)</span> then <span class="math inline">\(P(A\cap B) = P(A)P(B) = P(\emptyset) = 0\)</span>. This only holds if either <span class="math inline">\(P(A) = 0\)</span> or <span class="math inline">\(P(B) = 0\)</span>. This may seem to be a rather technical point, however, it is the source of much confusion regarding independence. In particular, it is common to mistake independent events for <strong>mutually exclusive events</strong>.</p>
<p>Suppose that my partner and I always eat dinner together. It will either be the case that I cook at home, that they cook at home, that we order in, or that we go out to eat. If we take these to be four events, <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, <span class="math inline">\(C\)</span>, and <span class="math inline">\(D\)</span>, then it reasonable to suggest that only one of these can happen on any given night. Whenever this is the case, we refer to the events as being mututally exclusive: if one happens, we know that the others did not. Mutually exclusive events are always dependent since knowing that <span class="math inline">\(A\)</span> occurs dramatically shifts our belief about <span class="math inline">\(B\)</span>,<span class="math inline">\(C\)</span>, and <span class="math inline">\(D\)</span> (namely, we now know that they are impossible).</p>
<p>The primary concern with mututally exclusive and independent events is a linguistic one. We often use words like independent to mean unrelated, and in a sense, mututally exclusive events are unrelated in that one has nothing to do with another. However, in statistics and probability, when we discuss independence, it is not an independence of the events themselves but rather an independence relating to our beliefs regarding the uncertainty associated with the events. In this sense, mutually exclusive events are very informative regarding the uncertainty associated with them.</p>
<p>TODO: Write example regarding mututally exclusive and independent events.</p>
</section>
<section id="contingency-tables" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="contingency-tables"><span class="header-section-number">4.3</span> Contingency Tables</h2>
<p>Through to this point we have discussed probabilities in the abstract, either through an enumeration of equally likely outcomes, or else by directly specifying the likelihood of various events. While these are useful in many regards, we are often looking for more concise manners of summarizing information of interest. One tool for accomplishing this is a <strong>contingency table</strong>. A contingency table summarizes teh frequency of occurence of a variable (or multiple variables) across a population of interest.</p>
<p>For instance, you could form a contingency table relaying the frequency with which undergraduate students are enrolled in various faculties at a particular university. This tells you, of the whole population of students at the university, what is the faculty breakdown. By dividing the number in each faculty by the total number of students, you convert the frequencies to proportions, and these proportions can be viewed as probabilities.</p>
<p>TODO: write-up frequency and prop table.</p>
<p>The interpretation of proportions as probabilities implies a very specific statistical experiment. In particular, the proportion represents the probability that an individual selected at random from the entire population has the given trait. This is frequently a probability of interest, which makes these summary tables a useful tool. Often, when a single trait is displayed we will not refer to them as contingency tables but rather as frequency tables or frequency distributions. A contingency table will typically plot two or more traits on the same table, with each cell representing the frequency of both traits occurring simultaneously in the population. For instance, we may further include the student’s years to see the breakdown of both faculty and year of study, in one table.</p>
<p>TODO: Include updated table</p>
<p>By including two (or more) factors on the table we are able to capture not only the marginal probabilities for the population, but also the joint probabilities for the population, and in turn, the conditional probabilities for the population. Being able to concisely summarize all of these concepts regarding traits in a population of interest renders contingency tables immensely useful in the study of uncertainty broadly.</p>
<p>TODO: Include example(s) of contingency tables.</p>
<p>Suppose we consider a two-way contingency table. Each cell consists of frequnecy with which a combination of two traits occurs in the population. If we take events corresponding to each of the levels of the two varaibles of interest, then these central cells represent the frequncy of joint events. That is, each interior cell gives the total number of observations with a set level for variable one AND a set level for variable two. Each row is summed, with the total number following into the corresponding row recorded in the right hand margin. each column is summed, with the total number corresponding to the given column recorded in the bottom margin. Then the margin totals are summed and the total is recorded in the lower right margin space.</p>
<p>TODO: Include graphic with summation of margins</p>
<p>Whether the rows or columns are summed, they should sum to the same total, which is the total of the population under consideeartion. This is the same as simply adding all of the observed interior frequencies. To turn a frequency into a probability, you need only divide the correct frquency by the correct total.</p>
<p>For the standard joint probabilities, you take the interior cell count and divide by the population total. Here we are saying that some fixed number, <span class="math inline">\(m\)</span>, of the <span class="math inline">\(N\)</span> total individuals have both traits under consideration. If instead you wish to find a marginal probability, you have to consider the value in the corresponding margin: this is the total number of individuals with the given trait, ignoring the level of the other variable. These marginal values are also divided by the total population size. For conditional probbailities, we restrict our focus to either only one row, or one column. Then, we can take teh joint cell and divide by the value in the margin, which gives the conditional probability of interest.</p>
<p>TODO: show probability caluclations for the various scenarios that we saw.</p>
<p>Note that these procedures are exactl in line with what we had seen before. The conditional probability is defined as the joint probability divided by the marginal probability. The process of computing the marginal can be seen as an application of the law of total probability. As a result, contingency tables can be a useful, tangible tool for investigating the techniques we have been discussing: they are not a substitutefor direct manipulation of the mathematical objedts, but they can present insight into the underlying processes where it may be hard to derive that insight otherwise.</p>
<p>TODO: show example of conditional probability derivation.</p>
<p>TODO: show example of law of total probabilitty derivation.</p>
<p>It is important to note that there is redundant information within a contingency table. For instance, the margins need not be listed explicit, as they can be directly calculated from the interior points. Same goes for interior points, given the margins of the table (assuming other interior points are also presented). TThis can be useful for a campact representation of the information, and manipulating these tables, finding the required information in many places, should become second anture as you continue to work with them more and more.</p>
<p>TODO: include fill-in-the-blank contingency table</p>
<p>It is also important to recognize that independence and mutually exclusive events can be codified via the table as well. Zeros on the interior points indicate events which are mutually exclusive: if we know that one of them occurred, we also know that the other one did not. For independence, it requires a degree of solving proportions. We can either check that the joint probability (<span class="math inline">\(N_{A,B}/N\)</span>) is equal to the product of the two marginal probabilities, (<span class="math inline">\(N_AN_B/N^2\)</span>), or else (assuming that the events are all non-zero), that the conditional probability (<span class="math inline">\(N_{A,B}/N_A\)</span>) equals the marginal probability <span class="math inline">\(N_B/N\)</span>. Either way this is represented by <span class="math inline">\(N\times N_{A,B} = N_AN_B\)</span>, and when this holds, we can conclude that the events are independent.</p>
<p>TODO: Example on mututally exclusive / independent events on a contingency table.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          trigger: 'click',
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          positionFixed: true,
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../notes/chapter3.html" class="pagination-link  aria-label=" &lt;span="" core="" concepts="" of="" probability&lt;="" span&gt;"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Core Concepts of Probability</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../notes/chapter5.html" class="pagination-link" aria-label="<span class='chapter-number'>5</span>&nbsp; <span class='chapter-title'>Random Variables</span>">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Random Variables</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>