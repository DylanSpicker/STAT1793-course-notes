{"title":"Continuous Random Variables","markdown":{"headingText":"Continuous Random Variables","containsRefs":false,"markdown":"Our discussions of probability distributions, and their summaries have focused entirely on discrete random variables. To recap, a discrete  random variable is any random quantity with a countable number of elements in the sample space. Discrete random variables are defined in contrast to continuous random variables, which take on values over the span of intervals in uncountably large sets. Suppose that $X$ can take any real number between $0$ and $1$. There is no  way to enumerate the set of possible values for this random quantity, and so it must not be discrete.\n\nMany quantities of interest are better  treated as a continuous quantity rather than a discrete one, even if this is not technically correct. For instance, time measured in seconds is often best thought of as continuous, even though any stop watch used to grab these measurements will have some limit to the precision with which it can measure. Similarily, lengths (or heights) will often be better treated as continuous quantities, even though any measuring device will necessarily have some minimal threshold afterwhich it cannot discern distances. Deciding whether a quantity is continuous or discrete can thus, sometimes, be a judgment call. In general discrete quantities are harder to work with when the set of possibilities is very large. In these cases, not much is lost by treating the random variables as though they were continuous. This distinction is another area which requires the active development of intuition, but once present, it becomes second nature.\n\nTODO: include examples for discrete versus continuous.\n\n## Continuous Versus Discrete\nDistinguishing whether a random quantity is continuous or discrete is crucial as, broadly speaking, the two types of quantities are treated differently. The same underlying ideas are present, but the distinctions between the two settings require some careful thought. As a general rule, the use of continuous random variables necessitates an understanding of introductory calculus. This is not a pre-requisite for this course, and as a result, we will not focus as deeply on working with the underlying quantities. However, continuous random variables are also the dominant type of random variables outside of introductory courses. As a result, understanding the distinctions, and beginning to become familair with how they are to be manipulated is an important skill.\n\nThe key difference between discrete and continuous random variables is that, for discrete random variables the beahviour is governed by assessing $P(X=x)$ for all possible values of $x$, and for continuous random variables $P(X=x)=0$ for every value of $x$. This is a surprising statement, and as such it is worth reiterating. With discrete random variables we discussed how all of the probabalistic behaviour was governed by the probability mass function which was defined as $p_X(x) = P(X=x)$. If $X$ is continuous, it will aalways be the case that $P(X=x) = 0$. Correspondingly, continuous random variables do not have probability mass functions, and to understand the behaviour of these random variables we must turn to other quantities.\n\nWhile the fact that $P(X=x) = 0$ may seem unintuitive at first glance, it is worth exploring this even  further. The nature of a continuous random variable is such that there is no possible way to enumerate all of the values which are possible to be realized by the random quantity. Suppose that we take a set of countably many possible observations and gave  each of these a probability of greater than $0$ of occuring directly. Even if we take an infinite number of them, there will still be an uncountably infinite number of events in the sample space which we have not accounted for. We know that the total probability of the sample space must be $1$, and so we must have the total probability of the first set of events being less than $1$ (if it summed to $1$ then this would not be a continuous random variable, since there would only be a countable number of possible events). Now suppose we take another set of countably many events, again giving each of them a positive probability. Once more the sum of all of these probabilities must be less than $1$, and specifically, the sum of both sets must also be less than $1$. Even after these two sets there are still uncountably infinite events to go, and so we continue this process. Because we always need the total probability to be $1$ once all events have been accounted for, and because we will always have an uncountably infinite number of events left to account for, we can **never** have a positive probability assigned to each event in a set of events. Even if we made the probability of each of these sets very, very small (say $1$ in a million) after some fixed number of countable eevents the probabilities would be greater than $1$ which cannot happen. As such, each event itself must have $0$ probability.\n\nAn alternative technique for understanding this intuition is to think about how uunlikely it really would be to observe any specific value. Suppose that $X$ takes values on the interval $[0,1]$. Recall that when we defined probabilities, we discussed them as being the long run proportion of time that an event occurs. Take some event,  say $X=0.5$. Suppose that we took repeated measurements of $X$ which are independent and identically distributed. Now suppose that at some point we exactly do observe $X=0.5$. Should we expect that this will ever happen again? The next time we get near $0.5$ might we instead not observe  $0.51$ or $0.49$ or $0.5000000000000000001$ or any of the other uncountably infinite values in the very near vicinity of $0.5$? Each time that we make an observation the denominator of our proportion is growing, but if every value between $0$ and $1$ is truly possible, as time goes on the number of times that $X=0.5$ must stay much, much smaller than the total number of trials. If we continue this off to infinity, in the limit, the probability must become $0$.\n\nThis conclusion leads to a few different points. First, impossibility is not the same as probability $0$. Impossible events do have probability $0$, but possible events may also have probability $0$. Events which are outside of the sample space are impossible. Events inside the sample space, even probability zero events, remain possible. Second, we require alternative mathematical tools for discussing the probability of events in a continuous setting. Ideally this would be analogous to a probability mass function, but would somehow function in the case of continuity.\n\n## Cumulative Distribution Functions\nTo begin building up to the continuous analogue to the probability mass function, we will start by focusing on events that are easier to define in the continuous case. Suppose that $X$ is defined on some continuous interval. Instead of thinking of events relating to $X=x$, we instead turn our focus to events of the form $X \\in (a,b)$ for some interval defined by the endpoints $a$ and $b$. Now note that, relying only on our knowledge of probabilities relating to generic events, we can rewrite $P(X\\in(a,b))$ slightly. Specifically, \\begin{align*}\nP(X\\in(a,b)) &= 1 - P(X\\not\\in(a,b))\\\\\n&= 1 - P(\\{X < a\\}\\cup\\{X > b\\}) \\\\\n&= 1 - \\left(P(X < a) + P(X > b)\\right)\\\\\n&= 1 - P(X > b) - P(X < a)\\\\\n&= P(X < b) - P(X < a).\\end{align*}\n\nTODO: diagram showing this graphically.\n\nIn words we know that the probability that $X$ falls into any particular interval is given by the probability that it is less than the upper bound of the interval  minus the probability that it is less than the lower bound of the interval. Notice that $X < a$ is an event, and if we knew how to assign probabilities to $X<a$ for arbitrary $a$, then we could assign probabilities to any interval. Also note that, even in the continuous case, it make sense to talk of $P(X < a)$ for some value $a$. These intervals will contain an uncountably infinite number of events,  and as  such, can certainly occur with greater than $0$ probability. Using our common example of $X$ being defined on $[0,1]$, then $P(X<1)=1$. Note that we could have written $P(X \\leq 1) = 1$, which may have been more obviously true. However, $P(X\\leq 1) = P(\\{X<1\\}\\cup\\{X=1\\}) = P(X<1) + P(X=1)$ and we know that $P(X=1)=0$. In the continuous case  we do not need to worry whether we use $X\\leq a$ or $X < a$,  and we will interchange them throughout.\n\nTODO: uniform example\n\nThe centrality of events of the form $X<a$ prompts the definition of a mathematical function which we call  the **cumulative distribution function**. We will typically denote the cumulative distribution function of a random variable $X$ as $F(x)$, sometimes using $F_X(x)$ to emphasize that this function relates to $X$ specifically. We may also refer to the cumulative distribution function simply as the **distribution function**. By definition, we take $F_X(x) = P(X\\leq x)$. Once we have defined the distribution function for a random variable, using the above derivation we are able to determine the probability associated with any events based on intervals.\n\nIt is worth noting that the cumulative distribution function can also be defined for discrete random variables. In the case of a discrete random variable, we would have $$F_X(x) = \\sum_{k \\in\\mathcal{X}; k \\leq x} p_X(k).$$ Since it is simply the summation of the probability mass function it tends to be a less useful quantity. Still, the cumulative distribution functions for discrete random variables do come up on ocassion,  and it is worth recognizing that they are defined in exactly the same way.\n\nTODO: Include example with the CDF.\n\nSupposing that, for some continuous random variable $X$  we have the cumulative distribution function, then thisknowledge actually permits us to compute *any* probability associated with the random variable that we can want. Consider any event associated with $X$ which we may wish to determine the probability of. We know that events are merely subsets of the sample space. Every one of these events can be written using our basic set operations (unions, intersections, and complements) applied to intervals of the form $(a,b)$ and **singelton sets** of the form $\\{x\\}$. Our basic axioms of probability allow us to compute probabilities across the set operations,  and our knowledge of the cumulative distribution, the conversion of $P(X \\in (a,b)) = F_X(b) - F_X(a)$, and the fact that $P(X=0) = 0$ gives  all of the results we need to derive probabilities for these  events.\n\nTODO: Include simple examples\n\n## The Probability Density Function\nThe distribution function will be the core object used to discuss the probabalistic behaviour of a continuous random variable. All of the beahviour of these random quantities will be described by the distribution function, and as such we will take the distribution function as a function which defines the distribution of a continuous random quantity. This is all that we need in orderto analyze the probabalistic behaviour of these random variables, however, it may be a little unsatisfying in contrast with the  discrete case.\n\nWe had set out to find a quantity which was a parllel to the probability mass function, and instead concluded that the cumulative distribution function can eb made to play the same role in terms of describing the behaviour of the random quantity. Still, it may be of interest for us to have a function which takes into account the relative likelihood of being near some value. Suppose, for instance, that for a random variable defined on $[0,1]$ we wanted to know how likely it was to be in the vicinity of $X=0.5$. We could take a small number, say $\\delta = 0.01$ and calculate $P(X\\in(0.5-\\delta,0.5+\\delta)) = F(0.5+\\delta)-F(0.5-\\delta)$. This is perfectly well defined based on our discussions to this point. Now, if we assume that the probability isfairly evenly distributed throughout this interval, then if we wanted to assign a likelihood to each value we could divide this total probability by hte length of the interval, which is $2\\delta$. As a result, we are saying that the probability that $X$ is nearly $0.5$ will be approximately given by the expression $\\frac{F(0.5+\\delta)-F(0.5-\\delta)}{2\\delta}$. \n\nWe had taken $\\delta=0.01$, but the same process could be applied for smaller and smaller $\\delta$, say $0.001$ or $0.0001$. Intuitively, as the size of this itnerval shrinks more and more we are getting a better and better estimate for the likelihood that the random variable is in the immediate vicinity of $0.5$. Moreover, as $\\delta$ gets smaller and smaller our assumption of a uniform probability over the interval becomes more and more reasonable. Now,, we cannot set $\\delta=0$ exactly, however, we can ask what happens in the limit as $\\delta$ continues to get smaller and smalller. This question is in the purvue of calculus, and can in fact be answered. While working out the answer is beyond the scope of the course, we will provide the result anyway.\n\nThe resulting function is called the **probability density function**, and is related to the cumulative distribution function through derivatives (and integrals). If a random variable $X$ has a cumulative distribution function, $F(x)$, we typically denote the corresponding density function as $f(x)$. The density function also describes the behaviour of the random variable, and mirrors the behaviour of the probability mass function in the discrete  case. Roughly speaking, the density function evaluates how likely (relatively speaking) it is for a continuous quantity to be in a small neighbourhood of the given value. Critically, **probability density functions do not give probabilities directly**. In fact, probability density functions may give values that are  greater than $1$!\n\nTODO: Example of uniform PDF.\n\nStill, if we see the shape of the probability density function, we can state how likely it is to make observations  near the results of interest. We will often graph the density function. The high points of the graph indicate regions with more probability than the regions of the graph which are lower. Again, the specific probability of any event $X=x$ will always be $0$, but some events fall in neighbourhoods which are more likely to observe than others.\n\nTODO: include examples.\n\n## Using Continuous Distributions\nWith the exception of the differences indicated until this point, there is otherwise not much difference between continuous and discrete random variables. The tools to analyze them differ (in the continuous case, we cannot sum over the sample space, and so we must use techniques from calculus to mirror this process, for instance), but the fundamentals remain the same. It is still possible to compute expected values (and medians and modes) with roughly the same interpretations. It is still possible to describe the range, interquartile range, and variance, again with corresponding interpretations. The axioms of probability still  underpin the manipulation and analysis of these random variables. The distinction is merely that in place of elementary mathematics to complete the calculations, calculus is required.\n\nJust as with discrete distributions, there are continuous named distributions. These are typically governed by either a density function or else a distribution function, alongside the expected value and variance. And just like the named  discrete distributions, by matching the underlying scenario to the correct process, we are able to side step a lot of work in understanding the beahviour of the random quantities. Now, because there is no assumed knowledge of calculus, we will not work too widely with continuous distributions. We will introduce only two named continuosu distributions: the uniform distribution, which we have already started to see, and the normal distribution, which is far and away the most important distribution (discrete or continuous) in all of probability and statistics.\n\n## The Uniform Distribution\nThe uniform distribution, sometimes called the continuous uniform distribution to distinguish it from the discrete counterpart, is parameterized over a set interval specified as $(a,b)$. On this interval, equal probability density is given to every event,  which is to say that the density function is constant. Specifically, for $X\\sim\\text{Unif}(a,b)$ we note that $$f(x) = \\begin{cases}\\frac{1}{b-a} & x \\in (a,b) \\\\ 0 & \\text{otherwise}.\\end{cases}$$ From the density function we can work out that $$F(x) = \\frac{x - a}{b - a}$$ for $x \\in (a,b)$, with $F(x) = 0$ for $x < a$ and $F(x) = 1$ for $x > b$. Moreover, we have $E[X] = \\frac{a+b}{2}$ and $\\var(X) = \\frac{(b-a)^2}{12}$.\n\nTODO: Include some calculations\n\nThe uniform distribution is analogous to the discrete uniform. Any time there is an interval of possible outcomes which are all equally likely, the uniform distribution is the distribution to use. Compared with other distributions it is also fairly straightforward to work with, which makes it a useful demonstration of the concepts relating the continuous probability calculations. \n\nTODO: Include examples.\n\n# The Normal Distribution\nThe normal distribution, also sometimes referred toas the Gaussian distribution, is a named continuous distribution function defined on the complete real line. The distribution is far and away the most prominently used distribution in all of probability and statistics. In fact, most people have heard of normal distributions even if they are not aware of this fact. Any time that there is a discussion of a bell curve, for instance, this is in reference to the normal distribution. Normally distributed quantities arise all over the place from measurements of heights, grades, or reaction times through to levels of job satisfaction, reading ability, or blood pressure. There is a tremendous number of normally distributed phenomena naturally occurring in the world, which renders the normal distribution deeply important across a wide range of domains.\n\nPerhaps more important than the places where the normal distribution arises in nature are hte places where it arises mathematically. At the end of this course we will see a result, the central limit theorem, which is one of the core results in all of statistics. Most of the statistical theory that drives scentific inquiry sits ontop of the central limit theorem, and at the core of the central limit theorem is the normal distribution. It is virtually impossible to overstate the importance of the normal distribution, and as a result, we will spend a great deal of time investigating it.\n\n## The Specification of the Distribution\nA normal distribution is parameterized by two different parameters: the mean, $\\mu$, and the varaince $\\sigma^2$. We write $X\\sim N(\\mu,\n\\sigma^2)$. These parameters directly correspond to the relevant quantities such that $E[X] =  \\mu$ and $\\var(X) = \\sigma^2$. The density function is given by $$f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right).$$ This can be quite unwieldy to work with, however, when it is plotted we ssee that the normal distribution takes on a bell curve which is centered at $\\mu$.\n\nTODO: include plots\n\n## The Standard Normal Distribution\nNormally distributed random variables are particularly well-behaved. One way in which this is true is that if you  multiply a normally distributed random variable by a constant, it will remain normally distributed, and if you add a constant to a normally distributed random variable, it will remain normally distributed. Consider then if $X\\sim N(\\mu,\\sigma^2)$, taking the quantity $X - \\mu$. We have seen in our discussions of expected values that $E[X-\\mu] = E[X]-\\mu = 0$. Furthermore, adding or subtracting a constant will not change the variance. Thus, $X-\\mu\\sim N(0,\\sigma^2)$. \n\nNow, consider dividing this by $\\sigma$, or equivalently, multiply by $\\frac{1}{\\sigma}$. The expected value of the new quantity will be  $\\frac{1}{\\sigma}\\times 0 = 0$, and the variance of the newquantity will be $\\frac{1}{\\sigma^2}\\times\\sigma^2 = 1$. Taken together then, if $X\\sim N(\\mu,\\sigma^2)$ then $$Z = \\frac{X - \\mu}{\\sigma} \\sim N(0,1).$$ This holds true for *any* starting normal distribution, with any mean or variance values. As a result,  this straightforward transformation allows us to discuss any normal distribution in terms of $N(0,1)$. We call this the **standard normal distribution**, and will typically use $Z$ to denote a random variable from the standard normal distriubtion. \n\nTODO: Include example\n\nIf $Z\\sim N(0,1)$, then we use a special notation for the density function and distribution function of $Z$. Specifically, we take the density function to be denoted $\\varphi(z)$ and the cumulative distribution function to be given by $P(Z \\leq z) = \\Phi(z)$. The cumulative distribution function does not have a nice form to be written down, however, it is a commonly applied enough function that many  computing languages have implemented it, including of course R.\n\nTODO: Demonstration of using *norm.\n\nThe utility in this is demonstrated by realizing that events can be converted using the same transformations. Specifically, suppose we have $X \\sim N(\\mu,\\sigma^2)$, and we want to find $P(X \\leq x)$. Note that, $X \\leq x$ must also mean that $$\\frac{X-\\mu}{\\sigma} \\leq \\frac{x - \\mu}{\\sigma},$$ simply by applying the same transformation to both sides. But we *know* that the left hand side of this inequality is exactly $Z$, a standard normal random variable with cumulative distribution function $\\Phi(z)$. Thus, $$P(X \\leq x) = P\\left(Z \\leq \\frac{x - \\mu}{\\sigma}\\right) = \\Phi\\left(\\frac{x-\\mu}{\\sigma}\\right).$$ Using this trick of **standardization** any normal probability can be converted into a probability regarding the standard normal, for which we can easily use computer software.\n\nTODO: Include normal calculation \nTODO: Include discussion of R calculating normal probabilities\n\nAs a result, combining our knowledge of continuous random variables, with the process of standardization we are able to calculate normal probabilities for any events relating to normally distributed random quantities. Moreover, since the shape of the normal distribution is so predictable, it is often easy to draw out the density function, and indicate on this graphic the probabilities of interest, which in turn helps with the required probability calculations. Calculating probabilities from normal distributions will remain a central component of working with statistics and probabilities beyond this course. Developing the skills and intuition at this point, through repeated practice is a key step in successfully navigating statistics here and beyond.\n\nTODO: another example.\n\nWhen you have access to a computer, and your interest is in calculating a normal probability, as described above, there is not properly a need for standardization. However, it rmeains an important skill for several reasons. First, by always working with the same normal distribution, you will develop a much more refined intuition for the likelihoods of different events. It goes beyond working with the same family of distributions, you get very used to working with exactly the same distribution. Second, you will likely become quite familiar with certain key **critical values** of the standard normal distribution. These values arise frequently, and allow you to quickly approximate the likelihood of different events. Finally, as we begin to move away from studying probability and into studying statistics, the standard normal will feature prominently there. \n\n## The Empirical Rule\nAnother way in which the normal distribution is well behaved is summarized in the **emprical rule**. The shape of the distribution is such that, no matter the specific mean or variance, all members of the family remain quite similar. This enables the derivation of an easy, approximate result, to help intuitively gauge the probabilities of normal events. The emprical rule states that, if $X$ has a normal distribution, then the probability of observing a value within $\\sigma$ or the mean is approximately $0.68$, the probability of observing a value within $2\\sigma$ of the mean is approximately $0.95$, and the probability of observing a value within $3\\sigma$ of the mean is approximately $0.997$.\n\nTODO: Include graphic\n\nIn words, the empirical simply states that almost all of the observations from a normal distribution will fall within $\\mu\\pm3\\sigma$. In mathematical terms, the empirical rule is summarized as $P(\\mu-\\sigma\\leq X \\leq \\mu + \\sigma) \\approx 0.68$, $P(\\mu - 2\\sigma \\leq X \\leq \\mu + 2\\sigma) \\approx 0.95$, and $P(\\mu - 3\\sigma \\leq X \\leq \\mu + 3\\sigma) \\approx 0.997$. With the standard normal we can replace $\\mu$ with $0$, and $\\sigma$ with $1$ to get a version which is slightly more concise to state. It is then possible to combine these different intervals by recognizing the symmetry in the normal distribution. That is, $P(\\mu \\leq X \\leq \\mu + \\sigma) \\approx \\frac{0.68}{2} = 0.34$. \n\nTODO: Calculations with the empirical rule.\n\nThe empirical rule is not exact, and again, when computing probabilities with access to statistical software, it is likely of limiteddirect utility. However, it is another tool to leverage to continue developing a refined intuition for the behaviour of random quantities. It is also a good check to  have a sense of the likelihood of different events. If you compute an answer which seems out of line with the empirical rule, take a look moreclosely. If you have someone tell you that they have observed events which are out of line with the empirical rule, be skeptical. \n\n### Chebyshev's Inequality\nThe empirical rule is a useful result to aid in building intuition regarding the normal distribution. However, when quantitiesare not normally distributed, we cannot use the empirical rule. A related, though somewhat weaker result, does hold for *any* distribution, and it is a useful extension to the empirical rule. Stated in words,  Chebyshev's inequality says that there is a probability of $0.75$ or more of observing an observation within two standard deviations, and a probability of at least $0.8889$ of observing a value within three standard deviations of the mean.\n\nFormally, we can write that $$P(\\mu - k\\sigma \\leq X \\leq \\mu + k\\sigma) \\geq 1 - \\frac{1}{k^2}.$$ Here $k$ can be any real number which is greater than $0$. If $k\\leq 1$, this result is uninteresting since the bound simply is $0$. However, taking $k=2$ gives the $0.75$ lower bound outlined above, which is a more useful result. Additionally, there is no requirement for $k$ to be an integer here, and so, for instance, the probability of observing a value within $\\mu\\pm\\sqrt{2}\\sigma$ is at least $0.5$, for all distributions.\n\nTODO: Include some examples.\n\n## Closure of the Normal Distribution\nWe have seen a certain type of \"closure property\" for the normal distribution when we discussed standardization. That is, adding and multiplying by constants does not change the distribution when working with normally distributed quantities. This is an interesting property which does not hold for most distributions, and makes normally distributed random variables quite nice to work  with. The normal distribution has an addition type of closure property which is frequently used, and is also somewhat surprising.\n\nSuppose that $x$ and $Y$ are independent of one another, with $X\\sim N(\\mu_X, \\sigma_X^2)$, and $Y\\sim N(\\mu_Y, \\sigma_Y^2)$. In this setting, $$X+Y\\sim N(\\mu_X+\\mu_Y, \\sigma_X^2 + \\sigma_Y^2).$$ in words, the addition of two independent normally distributed random variables will also be normally distributed. This extends beyond two in the natural way, simply by applying and reapplying the rule (as many times as is required).\n\nTODO: Include example of this.\n\nThis becomes particularly useful when we think of generating many iid realizations in an experiment from a normal population. For instance, if $X_1,\\dots,X_n$ are all iid from a $N(\\mu,\\sigma^2)$ distribution, then $$\\sum_{i=1}^n X_i \\sim N(n\\mu, n\\sigma^2).$$ If instead we consider the  average of these $n$ independent variables, then $$\\frac{1}{n}\\sum_{i=1}^n X_i \\sim N(\\mu, \\frac{\\sigma^2}{n}),$$ through an application of our standard expectation and variance transformation rules. This type of result is central to the practice of statistics, and this closure under addition further aids in the utility of the normal distribution.\n\n## Normal Approximations\nA final utility to the normal distribution is in its ability to approximate other distributions. While several of these approximations exist, we will focus on the normal approximation to the binomial as an illustrative example. Historically, these approximations were critical for computing probabilities by hand in a timely fashion. Owing to the widespread use of statistical software, these usecases are more and more limited, which removes the necessity of these approximations directly. However, there  are two major advantages to learning these approximations. First, with an approximation it becomes easier to leverage the intuition you will build regarding the normal distribution in order to better understand the behaviour of other random quantities. Second, the normal approximation has the same \"flavour\" as many results in statistics, and so it presents an additional path to familiarity with these types of findings.\n\nSuppose that $X\\sim\\text{Bin}(n,p)$. Through knowledge of the binomial distribution, we know that $E[X] = np$ and $\\var(X) = np(1-p)$. If $n$ is sufficiently large then it is possible to approximate a binomial distribution using a normal distribution with the corresponding mean and variance. That is, for $n$ large enough, we can take $X\\sim\\text{Bin}(n,p)$ to have approximately the same distribution as $W\\sim N(np, np(1-p))$.\n\nTODO: Brief example.\n\nOne consideration that we need to make when  applying this approximation has to do with the fact that the normal distribution is continuous while the binomial distribution is discrete. As a result, the normal distribution can take on any value on the real line, where the binomial is limited to the integers. A question that we must answer is what to do with the non-integer valued numbers. The natural solution is to rely on rounding. That is, for any value between $[1.5, 2.5)$ we would round to the nearest integer, which is $2$. \n\nThis natural solution is in fact a fairly useful technique, and it is the one that we will make use of in the normal approximation. While rounding is quite natural, the process for leveraging this idea in probability approximation is somewhat backwards. That is, we typically will need to go from probabilities relating to $X$ and transform those into probabilities relating to $W$. So, for instance, if we wish to know $P(X \\leq 2)$, then we need to be able to make this a statement regarding the random variable $W$. In order to do this we need to ask \"what is the largest value for $W$ that would get rounded to $2$?\" The answer is $2.5$ and so $P(X \\leq 2) \\approx P(W \\leq 2.5)$.\n\nA similar adjustment would be required if we instead wanted $P(X \\geq 5)$. Here we would ask \"what is the smallest value for $W$ which would get rounded to $5$?\" and note that the answer is $4.5$. Thus, $P(X \\geq 5) \\approx P(W \\geq 4.5)$. Once  we have expressed the probability of interest in terms of the normla random variable, we can use the standard techniques previously outlined to compute the relevant probabilities.\n\nTODO: Examples\n\nIt is very important to keep in mind that the two results discussed above were of the form $X \\geq x$ and $X \\leq x'$. If we instead had considered $X > x$ or $X < x'$, we would need to take an additional step. For continuous random variables whether $X \\geq x$ or $X > x$ is considered it makes no difference. However, for discrete random variables this is not the case. As a result we should first convert the event the an equivalent event which contains the equality sign within the inequality, and then apply the continuity correction. (TODO: ensure that continuity correction was referenced before). That is, if we want $P(X > 3)$ first note that for $X > 3$ to hold, we could equivalently write this as $X \\geq 4$. Alternatively, if the event of interest is $X < 8$, this is the same as $X \\leq 7$.\n\nTODO: Further examples.\n\nWhen it is not necessary, it rarely makes sense to use an approximation. There will be cases where the approximation is directly useful, and in those moments it is great to be able to use it. This example of using the normal distribution to approximate a discrete random variable serves as a nice bridge from the study of probability to the study of statistics. In statistics we take a different view of the types of problems we have been considering to date, and we require the tools of probability that have been brought forth. As a result, a deep comfort with manipulating probability expressions is required to build a strong foundation while studying statistics.","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","filters":["webr"],"output-file":"chapter6.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.533","bibliography":["../references.bib"],"theme":["cosmo","../custom.scss"],"code-annotations":"select"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","filters":["webr"],"output-file":"chapter6.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"block-headings":true,"bibliography":["../references.bib"],"documentclass":"scrreprt"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}